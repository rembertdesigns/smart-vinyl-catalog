{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787f7d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /Users/richpointofview/smart-vinyl-catalog/notebooks\n",
      "Project root: /Users/richpointofview/smart-vinyl-catalog\n",
      "üéµ Smart Vinyl Catalog - Data Exploration\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Smart Vinyl Catalog - Data Exploration\n",
    "## Sprint 1: Foundation & Data Pipeline\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.insert(0, os.path.join(project_root, 'src'))\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Load environment from project root\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join(project_root, '.env'))\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from config.bigquery_config import config\n",
    "\n",
    "print(\"üéµ Smart Vinyl Catalog - Data Exploration\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb486fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BigQuery connection working\n",
      "Available datasets: 1\n",
      "  - vinyl_catalog\n"
     ]
    }
   ],
   "source": [
    "# Test BigQuery connection\n",
    "try:\n",
    "    # Force create a completely new client\n",
    "    from google.cloud import bigquery\n",
    "    from google.oauth2 import service_account\n",
    "    import os\n",
    "    \n",
    "    credentials_path = \"/Users/richpointofview/smart-vinyl-catalog/service-account-key.json\"\n",
    "    credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "    client = bigquery.Client(credentials=credentials, project=\"smart-vinyl-catalog\")\n",
    "    \n",
    "    # Test basic query\n",
    "    test_query = \"SELECT 1 as test_number\"\n",
    "    result = client.query(test_query).to_dataframe()\n",
    "    print(\"‚úÖ BigQuery connection working\")\n",
    "    \n",
    "    # List datasets\n",
    "    datasets = list(client.list_datasets())\n",
    "    print(f\"Available datasets: {len(datasets)}\")\n",
    "    for dataset in datasets:\n",
    "        print(f\"  - {dataset.dataset_id}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d121e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared queries for collection analysis:\n",
      "1. Complete collection overview\n",
      "2. Genre and style breakdown\n",
      "3. Ready for AI processing once authentication is resolved\n",
      "\n",
      "Next steps after fixing authentication:\n",
      "- Test AI functions (may be active by now)\n",
      "- Create personal collection tables\n",
      "- Process messy notes with AI extraction\n",
      "- Build recommendation foundation\n"
     ]
    }
   ],
   "source": [
    "# Sprint 1 Day 2 Analysis - Prepare queries for when connection is fixed\n",
    "\n",
    "# Query 1: Complete collection overview\n",
    "collection_analysis_query = \"\"\"\n",
    "SELECT \n",
    "    dr.title,\n",
    "    dr.artist,\n",
    "    dr.year,\n",
    "    dr.label,\n",
    "    ar.rating as critic_rating,\n",
    "    ar.review_text\n",
    "FROM `vinyl_catalog.discogs_releases` dr\n",
    "JOIN `vinyl_catalog.album_reviews` ar \n",
    "    ON dr.release_id = ar.album_id\n",
    "ORDER BY dr.year ASC\n",
    "\"\"\"\n",
    "\n",
    "# Query 2: Genre and style analysis\n",
    "genre_analysis_query = \"\"\"\n",
    "SELECT \n",
    "    genre,\n",
    "    style,\n",
    "    COUNT(*) as album_count,\n",
    "    AVG(ar.rating) as avg_rating\n",
    "FROM `vinyl_catalog.discogs_releases` dr\n",
    "JOIN `vinyl_catalog.album_reviews` ar ON dr.release_id = ar.album_id\n",
    "GROUP BY genre, style\n",
    "ORDER BY avg_rating DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"Prepared queries for collection analysis:\")\n",
    "print(\"1. Complete collection overview\")\n",
    "print(\"2. Genre and style breakdown\") \n",
    "print(\"3. Ready for AI processing once authentication is resolved\")\n",
    "\n",
    "print(\"\\nNext steps after fixing authentication:\")\n",
    "print(\"- Test AI functions (may be active by now)\")\n",
    "print(\"- Create personal collection tables\")\n",
    "print(\"- Process messy notes with AI extraction\")\n",
    "print(\"- Build recommendation foundation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b880816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Data:\n",
      "         title              artist  year     label  critic_rating                                                                                                   review_text\n",
      "    Blue Train       John Coltrane  1957 Blue Note            4.4                 A hard bop classic featuring Coltrane at his most accessible. Perfect rhythm section support.\n",
      "Somethin' Else Cannonball Adderley  1958 Blue Note            4.3                 Adderley's alto sax shines in this soul jazz gem. Balances sophistication with accessibility.\n",
      "  Kind of Blue         Miles Davis  1959  Columbia            4.8              A masterpiece of cool jazz. Davis's muted trumpet creates an atmosphere of contemplative beauty.\n",
      "   Giant Steps       John Coltrane  1960  Atlantic            4.6            Complex harmonic structures that challenged jazz conventions. Coltrane's technical prowess shines.\n",
      "A Love Supreme       John Coltrane  1965  Impulse!            4.9 Coltrane's spiritual journey manifests in four powerful movements. Represents the pinnacle of his expression.\n",
      "\n",
      "Total albums: 5\n"
     ]
    }
   ],
   "source": [
    "# Test your existing data\n",
    "if 'client' in globals():\n",
    "    # Run the collection overview query\n",
    "    try:\n",
    "        result = client.query(collection_analysis_query).to_dataframe()\n",
    "        print(\"Collection Data:\")\n",
    "        print(result.to_string(index=False))\n",
    "        print(f\"\\nTotal albums: {len(result)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Query failed: {e}\")\n",
    "else:\n",
    "    print(\"Client not available - fix connection first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315cc235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AI capabilities...\n",
      "AI functions still activating: 400 Table-valued function is not expected here: AI.GENERATE_TEXT; Did you mean ai.generate_int? at [2:8]; reason: invalidQuery, location: query, message: Table-valued function is not expected here: AI.GENERATE_TEXT; Did you mean ai.generate_int? at [2:8]\n",
      "\n",
      "Location: US\n",
      "Job ID: 65f030f6-57cf-4596-ad61-8a6d98116ba0\n",
      "\n",
      "\n",
      "AI Status: Still activating - continue with data prep\n"
     ]
    }
   ],
   "source": [
    "# Test BigQuery AI functions (Day 2 focus)\n",
    "print(\"Testing AI capabilities...\")\n",
    "\n",
    "# Test 1: Simple AI generation\n",
    "ai_test_query = \"\"\"\n",
    "SELECT AI.GENERATE_TEXT(\n",
    "    'Describe the musical style of hard bop jazz in one sentence'\n",
    ") AS description\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = client.query(ai_test_query).to_dataframe()\n",
    "    print(\"‚úÖ AI.GENERATE_TEXT is working!\")\n",
    "    print(\"Response:\", result['description'].iloc[0])\n",
    "    ai_ready = True\n",
    "except Exception as e:\n",
    "    print(f\"AI functions still activating: {e}\")\n",
    "    ai_ready = False\n",
    "\n",
    "# If AI is working, test with your actual data\n",
    "if ai_ready:\n",
    "    album_analysis_query = \"\"\"\n",
    "    SELECT \n",
    "        title,\n",
    "        artist,\n",
    "        AI.GENERATE_TEXT(\n",
    "            'Categorize this album as \"mellow\", \"intense\", or \"experimental\" based on the title and artist: ' || \n",
    "            title || ' by ' || artist\n",
    "        ) AS ai_category\n",
    "    FROM `vinyl_catalog.discogs_releases`\n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = client.query(album_analysis_query).to_dataframe()\n",
    "        print(\"\\nüéµ AI Album Categorization:\")\n",
    "        print(result.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Album analysis failed: {e}\")\n",
    "\n",
    "print(f\"\\nAI Status: {'Ready for processing' if ai_ready else 'Still activating - continue with data prep'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f1524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table: personal_collection\n",
      "Created table: raw_collection_notes\n"
     ]
    }
   ],
   "source": [
    "# Create personal collection tables for messy data processing\n",
    "def create_remaining_tables():\n",
    "    tables_schema = {\n",
    "        'personal_collection': [\n",
    "            ('collection_id', 'STRING'),\n",
    "            ('release_id', 'STRING'), \n",
    "            ('purchase_date', 'DATE'),\n",
    "            ('purchase_price', 'FLOAT'),\n",
    "            ('condition', 'STRING'),\n",
    "            ('listening_notes', 'STRING'),\n",
    "            ('personal_rating', 'INTEGER'),\n",
    "            ('times_played', 'INTEGER')\n",
    "        ],\n",
    "        'raw_collection_notes': [\n",
    "            ('note_id', 'STRING'),\n",
    "            ('raw_text', 'STRING'),\n",
    "            ('note_type', 'STRING'),\n",
    "            ('created_date', 'TIMESTAMP')\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for table_name, schema_list in tables_schema.items():\n",
    "        table_id = f\"{client.project}.vinyl_catalog.{table_name}\"\n",
    "        schema = [bigquery.SchemaField(name, field_type) for name, field_type in schema_list]\n",
    "        table = bigquery.Table(table_id, schema=schema)\n",
    "        \n",
    "        try:\n",
    "            client.create_table(table)\n",
    "            print(f\"Created table: {table_name}\")\n",
    "        except Exception as e:\n",
    "            if \"Already Exists\" in str(e):\n",
    "                print(f\"Table {table_name} already exists\")\n",
    "            else:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "create_remaining_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89305774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing alternative AI syntax...\n",
      "ML.GENERATE_TEXT: 400 Table-valued function is not expected here: ML.GENERATE_TEXT at [2:8]; reason: invalidQuery, location: query, message: Table-valued function is not expected here: ML.GENERATE_TEXT at [2:8]\n",
      "\n",
      "Location: US\n",
      "Job ID: f2d04467-3ea4-465f-9f51-5ca925c3b155\n",
      "\n",
      "Creating personal collection data for upload...\n"
     ]
    }
   ],
   "source": [
    "# Test alternative AI function syntax\n",
    "print(\"Testing alternative AI syntax...\")\n",
    "\n",
    "# Try the newer ML.GENERATE_TEXT syntax\n",
    "ml_test_query = \"\"\"\n",
    "SELECT ML.GENERATE_TEXT(\n",
    "    'Describe jazz music briefly',\n",
    "    STRUCT(\n",
    "        0.3 AS temperature,\n",
    "        100 AS max_output_tokens\n",
    "    )\n",
    ") AS description\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = client.query(ml_test_query).to_dataframe()\n",
    "    print(\"ML.GENERATE_TEXT working!\")\n",
    "    print(\"Response:\", result['description'].iloc[0])\n",
    "    ml_ready = True\n",
    "except Exception as e:\n",
    "    print(f\"ML.GENERATE_TEXT: {e}\")\n",
    "    ml_ready = False\n",
    "\n",
    "# Since AI functions aren't ready, let's prepare for Sprint 2\n",
    "# Upload the messy collection data we created earlier\n",
    "if 'messy_notes_df' in globals() and 'personal_df' in globals():\n",
    "    try:\n",
    "        # Add timestamp to messy notes\n",
    "        messy_notes_df['created_date'] = datetime.now()\n",
    "        \n",
    "        # Upload both datasets\n",
    "        upload_dataframe_to_bq(messy_notes_df, 'raw_collection_notes')\n",
    "        upload_dataframe_to_bq(personal_df, 'personal_collection')\n",
    "        print(\"Personal collection data uploaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Upload error: {e}\")\n",
    "else:\n",
    "    print(\"Creating personal collection data for upload...\")\n",
    "    # We'll recreate this data since kernel was restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b439bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created messy collection notes for AI processing\n",
      "Created personal collection with purchase history\n",
      "Notes: 5 entries\n",
      "Collection: 5 albums\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Recreate personal collection data (lost during kernel restart)\n",
    "messy_collection_notes = [\n",
    "    {\n",
    "        'note_id': 'NOTE_001',\n",
    "        'raw_text': 'Miles Davis - Kind of Blue, Columbia pressing, 1959, bought for $28 at Fingerprints Music, condition VG+, sounds incredible',\n",
    "        'note_type': 'purchase_record'\n",
    "    },\n",
    "    {\n",
    "        'note_id': 'NOTE_002', \n",
    "        'raw_text': 'John Coltrane A Love Supreme - Impulse original pressing - $45 - mint condition - spiritual masterpiece - found at estate sale',\n",
    "        'note_type': 'purchase_record'\n",
    "    },\n",
    "    {\n",
    "        'note_id': 'NOTE_003',\n",
    "        'raw_text': 'Giant Steps Atlantic Records John Coltrane 1960 $35 very good condition complex harmonies challenging but rewarding',\n",
    "        'note_type': 'listening_notes'\n",
    "    },\n",
    "    {\n",
    "        'note_id': 'NOTE_004',\n",
    "        'raw_text': 'Blue Train Blue Note Coltrane 1957 Near Mint $32 hard bop classic great for late night listening perfect rhythm',\n",
    "        'note_type': 'listening_notes'\n",
    "    },\n",
    "    {\n",
    "        'note_id': 'NOTE_005',\n",
    "        'raw_text': 'Somethin Else Cannonball Adderley Blue Note 1958 Good+ condition $25 soul jazz gem Miles Davis on trumpet',\n",
    "        'note_type': 'discovery_notes'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Personal collection with purchase history\n",
    "personal_collection_data = []\n",
    "start_date = datetime(2020, 1, 1)\n",
    "\n",
    "for i, release_id in enumerate(['123456', '234567', '345678', '456789', '567890']):\n",
    "    days_offset = i * 120 + random.randint(0, 60)\n",
    "    purchase_date = start_date + timedelta(days=days_offset)\n",
    "    \n",
    "    base_prices = [28, 45, 35, 32, 25]\n",
    "    conditions = ['VG+', 'Mint', 'VG', 'Near Mint', 'Good+']\n",
    "    \n",
    "    listening_notes = [\n",
    "        'Perfect for late night sessions. The trumpet tone is phenomenal.',\n",
    "        'Spiritual journey in four movements. Life-changing album.',\n",
    "        'Complex but rewarding. Takes multiple listens to appreciate.',\n",
    "        'Hard bop at its finest. Great entry point for jazz.',\n",
    "        'Soul jazz with incredible energy. Miles Davis feature amazing.'\n",
    "    ]\n",
    "    \n",
    "    personal_collection_data.append({\n",
    "        'collection_id': f'PC_{i+1:03d}',\n",
    "        'release_id': release_id,\n",
    "        'purchase_date': purchase_date.strftime('%Y-%m-%d'),\n",
    "        'purchase_price': base_prices[i],\n",
    "        'condition': conditions[i],\n",
    "        'listening_notes': listening_notes[i],\n",
    "        'personal_rating': random.randint(8, 10),\n",
    "        'times_played': random.randint(15, 45)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrames\n",
    "messy_notes_df = pd.DataFrame(messy_collection_notes)\n",
    "personal_df = pd.DataFrame(personal_collection_data)\n",
    "\n",
    "print(\"Created messy collection notes for AI processing\")\n",
    "print(\"Created personal collection with purchase history\")\n",
    "print(f\"Notes: {len(messy_notes_df)} entries\")\n",
    "print(f\"Collection: {len(personal_df)} albums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b215eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define upload function and upload personal collection data\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def upload_dataframe_to_bq(df, table_name):\n",
    "    table_id = f\"{client.project}.vinyl_catalog.{table_name}\"\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "    job.result()\n",
    "    \n",
    "    print(f\"Uploaded {len(df)} rows to {table_name}\")\n",
    "\n",
    "# Upload personal collection data\n",
    "try:\n",
    "    # Add timestamp to notes\n",
    "    messy_notes_df['created_date'] = datetime.now()\n",
    "    \n",
    "    # Upload both datasets\n",
    "    upload_dataframe_to_bq(messy_notes_df, 'raw_collection_notes')\n",
    "    upload_dataframe_to_bq(personal_df, 'personal_collection')\n",
    "    \n",
    "    print(\"Successfully uploaded personal collection data\")\n",
    "    print(\"Ready for AI processing when functions activate\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Upload error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
