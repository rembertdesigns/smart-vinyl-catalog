{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb53da55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/richpointofview/smart-vinyl-catalog\n",
      "Discogs directory: /Users/richpointofview/smart-vinyl-catalog/data/discogs\n",
      "Processed directory: /Users/richpointofview/smart-vinyl-catalog/data/processed\n",
      "Loaded existing catalog: 55,000 records\n",
      "Current columns: ['release_id', 'title', 'artist', 'album', 'genre', 'year', 'duration', 'tags', 'plays', 'favorites', 'license', 'popularity_score', 'rating', 'label', 'country', 'review_text', 'review_source', 'source', 'catalog_number', 'discogs_id', 'format', 'status', 'release_videos_video_embed', 'release_labels_label_name', 'release_videos_video_duration', 'tracklist_track_position', 'companies_company_resource_url', 'release_labels_label_id', 'releases_release_data_quality', 'companies_company_catno', 'sub_tracks_track_title', 'release_formats_format_text', 'companies_company_name', 'releases_release_title', 'artists_artist_id', 'releases_release_released', 'companies_company_entity_type_name', 'artists_artist_join', 'releases_release_country', 'extraartists_artist_anv', 'releases_release_notes', 'release_videos_video_src', 'release_identifiers_identifier_description', 'artists_artist_anv', 'artists_artist_name', 'release_formats_format_qty', 'sub_tracks_track_position', 'releases_release_id', 'release_identifiers_identifier_value', 'releases_release_status', 'extraartists_artist_name', 'tracklist_track_duration', 'extraartists_artist_role', 'videos_video_description', 'releases_release_master_id', 'videos_video_title', 'format_descriptions_description', 'release_labels_label_catno', 'release_styles_style', 'release_formats_format_name', 'companies_company_entity_type', 'extraartists_artist_id', 'extraartists_artist_tracks', 'tracklist_track_title', 'release_series_series_id', 'release_series_series_name', 'sub_tracks_track_duration', 'release_series_series_catno', 'release_identifiers_identifier_type', 'releases_release_master_id_is_main_release', 'companies_company_id', 'release_genres_genre']\n",
      "Memory usage: 286.8 MB\n",
      "\n",
      "Discogs files available:\n",
      "  ‚úÖ artists: discogs_20250901_artists.csv (1.1 GB)\n",
      "  ‚úÖ labels: discogs_20250901_labels.csv (0.2 GB)\n",
      "  ‚úÖ masters: discogs_20250901_masters.csv (2.0 GB)\n",
      "  ‚úÖ releases: discogs_20250901_releases.csv (30.0 GB)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - Setup and Load Existing Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DISCOGS_DIR = DATA_DIR / 'discogs'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Discogs directory: {DISCOGS_DIR}\")\n",
    "print(f\"Processed directory: {PROCESSED_DIR}\")\n",
    "\n",
    "# Load existing combined catalog\n",
    "existing_catalog_path = PROCESSED_DIR / 'final_combined_catalog_real_data.csv'\n",
    "\n",
    "if existing_catalog_path.exists():\n",
    "    existing_catalog = pd.read_csv(existing_catalog_path, low_memory=False)\n",
    "    print(f\"Loaded existing catalog: {len(existing_catalog):,} records\")\n",
    "    \n",
    "    # Show current structure\n",
    "    print(f\"Current columns: {list(existing_catalog.columns)}\")\n",
    "    print(f\"Memory usage: {existing_catalog.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "else:\n",
    "    print(\"Error: Existing catalog not found. Run the integration notebook first.\")\n",
    "    existing_catalog = None\n",
    "\n",
    "# Check available Discogs files\n",
    "discogs_files = {\n",
    "    'artists': DISCOGS_DIR / 'discogs_20250901_artists.csv',\n",
    "    'labels': DISCOGS_DIR / 'discogs_20250901_labels.csv', \n",
    "    'masters': DISCOGS_DIR / 'discogs_20250901_masters.csv',\n",
    "    'releases': DISCOGS_DIR / 'discogs_20250901_releases.csv'\n",
    "}\n",
    "\n",
    "print(\"\\nDiscogs files available:\")\n",
    "for name, path in discogs_files.items():\n",
    "    if path.exists():\n",
    "        size_gb = path.stat().st_size / (1024**3)\n",
    "        print(f\"  ‚úÖ {name}: {path.name} ({size_gb:.1f} GB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {name}: Not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Process Artists Data from CSV\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def process_artists_data_final(artists_csv_path, sample_size=10000):\n",
    "    print(f\"Processing artists data from CSV (sample size: {sample_size})...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the CSV data\n",
    "        df_raw = pd.read_csv(artists_csv_path, low_memory=False)\n",
    "        print(f\"‚úÖ Loaded {len(df_raw):,} total artists from: {artists_csv_path.name}\")\n",
    "        \n",
    "        # Sample data\n",
    "        sample_data = df_raw.sample(n=min(sample_size, len(df_raw)), random_state=42).copy()\n",
    "        \n",
    "        processed_artists = []\n",
    "\n",
    "        for i, artist in sample_data.iterrows():\n",
    "            try:\n",
    "                artist_id = artist.get('id') or artist.get('artist_id')\n",
    "                name = artist.get('name') or artist.get('artist_name')\n",
    "                real_name = artist.get('realname') or artist.get('real_name')\n",
    "\n",
    "                profile = str(artist.get('profile')) if pd.notna(artist.get('profile')) else ''\n",
    "                urls = str(artist.get('urls')) if pd.notna(artist.get('urls')) else ''\n",
    "                urls_str = urls[:200] if urls else ''\n",
    "                \n",
    "                name_variations = artist.get('namevariations') or artist.get('name_variations')\n",
    "                name_variations_str = str(name_variations)[:200] if pd.notna(name_variations) else ''\n",
    "\n",
    "                aliases = artist.get('aliases', '')\n",
    "                aliases_str = str(aliases)[:200] if pd.notna(aliases) else ''\n",
    "\n",
    "                members = artist.get('members', '')\n",
    "                members_str = str(members)[:200] if pd.notna(members) else ''\n",
    "\n",
    "                groups = artist.get('groups', '')\n",
    "                groups_str = str(groups)[:200] if pd.notna(groups) else ''\n",
    "\n",
    "                images = artist.get('images', '')\n",
    "                image_count = 1 if pd.notna(images) and str(images).strip() else 0\n",
    "\n",
    "                # Quality score\n",
    "                quality_score = sum([\n",
    "                    bool(name), bool(real_name), bool(profile), bool(urls_str),\n",
    "                    bool(name_variations_str), bool(aliases_str),\n",
    "                    bool(members_str), image_count > 0\n",
    "                ])\n",
    "\n",
    "                processed_artist = {\n",
    "                    'artist_id': artist_id,\n",
    "                    'name': name,\n",
    "                    'real_name': real_name,\n",
    "                    'profile': profile[:500],\n",
    "                    'urls': urls_str,\n",
    "                    'name_variations': name_variations_str,\n",
    "                    'aliases': aliases_str,\n",
    "                    'members': members_str,\n",
    "                    'groups': groups_str,\n",
    "                    'image_count': image_count,\n",
    "                    'quality_score': quality_score,\n",
    "                    'has_profile': bool(profile),\n",
    "                    'has_real_name': bool(real_name),\n",
    "                    'has_variations': bool(name_variations_str),\n",
    "                    'has_aliases': bool(aliases_str),\n",
    "                    'has_members': bool(members_str),\n",
    "                    'has_groups': bool(groups_str)\n",
    "                }\n",
    "\n",
    "                processed_artists.append(processed_artist)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing row {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "        df_artists = pd.DataFrame(processed_artists)\n",
    "\n",
    "        print(f\"\\n‚úÖ Successfully processed {len(df_artists)} artists\")\n",
    "        print(f\"Average quality score: {df_artists['quality_score'].mean():.2f}\")\n",
    "        print(f\"Artists with profiles: {df_artists['has_profile'].sum()}\")\n",
    "        print(f\"Artists with real names: {df_artists['has_real_name'].sum()}\")\n",
    "        print(f\"Artists with name variations: {df_artists['has_variations'].sum()}\")\n",
    "        print(f\"Artists with aliases: {df_artists['has_aliases'].sum()}\")\n",
    "\n",
    "        # Save processed data\n",
    "        output_path = PROCESSED_DIR / 'processed_artists.csv'\n",
    "        df_artists.to_csv(output_path, index=False)\n",
    "        print(f\"üìÅ Saved processed artists data to '{output_path}'\")\n",
    "\n",
    "        return df_artists\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to process artists data\")\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run processing\n",
    "artists_csv_path = DISCOGS_DIR / 'discogs_20250901_artists.csv'\n",
    "df_artists = process_artists_data_final(artists_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc84978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Process Labels Data from CSV\n",
    "\n",
    "def process_labels_data(labels_csv_path, sample_size=10000):\n",
    "    print(f\"Processing labels data from CSV (sample size: {sample_size})...\")\n",
    "\n",
    "    try:\n",
    "        df_raw = pd.read_csv(labels_csv_path, low_memory=False)\n",
    "        print(f\"‚úÖ Loaded {len(df_raw):,} total labels from: {labels_csv_path.name}\")\n",
    "\n",
    "        sample_data = df_raw.sample(n=min(sample_size, len(df_raw)), random_state=42).copy()\n",
    "\n",
    "        processed_labels = []\n",
    "\n",
    "        for i, label in sample_data.iterrows():\n",
    "            try:\n",
    "                label_id = label.get('id') or label.get('label_id')\n",
    "                label_name = label.get('name') or label.get('label_name')\n",
    "                contact_info = label.get('contact_info', '')\n",
    "                parent_label_id = label.get('parent_label_id') if 'parent_label_id' in label else None\n",
    "                profile = str(label.get('profile')) if pd.notna(label.get('profile')) else ''\n",
    "                data_quality = label.get('data_quality', '')\n",
    "\n",
    "                processed_label = {\n",
    "                    'label_id': label_id,\n",
    "                    'label_name': label_name,\n",
    "                    'contact_info': contact_info,\n",
    "                    'parent_label_id': parent_label_id,\n",
    "                    'profile': profile[:500],\n",
    "                    'data_quality': data_quality\n",
    "                }\n",
    "\n",
    "                processed_labels.append(processed_label)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing label row {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "        df_labels = pd.DataFrame(processed_labels)\n",
    "\n",
    "        print(f\"\\n‚úÖ Successfully processed {len(df_labels)} labels\")\n",
    "        output_path = PROCESSED_DIR / 'processed_labels.csv'\n",
    "        df_labels.to_csv(output_path, index=False)\n",
    "        print(f\"üìÅ Saved processed labels data to '{output_path}'\")\n",
    "\n",
    "        return df_labels\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to process labels data\")\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run processing\n",
    "labels_csv_path = DISCOGS_DIR / 'discogs_20250901_labels.csv'\n",
    "df_labels = process_labels_data(labels_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 - Process Masters Data from CSV\n",
    "\n",
    "def process_masters_data(masters_csv_path, sample_size=10000):\n",
    "    print(f\"Processing masters data from CSV (sample size: {sample_size})...\")\n",
    "\n",
    "    try:\n",
    "        df_raw = pd.read_csv(masters_csv_path, low_memory=False)\n",
    "        print(f\"‚úÖ Loaded {len(df_raw):,} total masters from: {masters_csv_path.name}\")\n",
    "\n",
    "        sample_data = df_raw.sample(n=min(sample_size, len(df_raw)), random_state=42).copy()\n",
    "\n",
    "        processed_masters = []\n",
    "\n",
    "        for i, master in sample_data.iterrows():\n",
    "            try:\n",
    "                master_id = master.get('id') or master.get('master_id')\n",
    "                original_year = master.get('year') or master.get('original_year')\n",
    "                main_release_id = master.get('main_release') or master.get('main_release_id')\n",
    "                num_versions = master.get('num_versions', 0)\n",
    "                master_title = master.get('title') or master.get('master_title')\n",
    "\n",
    "                processed_master = {\n",
    "                    'master_id': master_id,\n",
    "                    'original_year': original_year,\n",
    "                    'main_release_id': main_release_id,\n",
    "                    'num_versions': num_versions,\n",
    "                    'master_title': master_title\n",
    "                }\n",
    "\n",
    "                processed_masters.append(processed_master)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing master row {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "        df_masters = pd.DataFrame(processed_masters)\n",
    "\n",
    "        print(f\"\\n‚úÖ Successfully processed {len(df_masters)} masters\")\n",
    "        output_path = PROCESSED_DIR / 'processed_masters.csv'\n",
    "        df_masters.to_csv(output_path, index=False)\n",
    "        print(f\"üìÅ Saved processed masters data to '{output_path}'\")\n",
    "\n",
    "        return df_masters\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to process masters data\")\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run processing\n",
    "masters_csv_path = DISCOGS_DIR / 'discogs_20250901_masters.csv'\n",
    "df_masters = process_masters_data(masters_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 - Filter High-Quality Releases from Existing Catalog\n",
    "\n",
    "def filter_high_quality_releases(df_catalog):\n",
    "    print(\"Filtering high-quality releases from existing catalog...\")\n",
    "\n",
    "    if df_catalog is None or df_catalog.empty:\n",
    "        print(\"‚ö†Ô∏è Catalog is empty or missing.\")\n",
    "        return None\n",
    "\n",
    "    # Convert columns safely to numeric\n",
    "    df_catalog['popularity_score'] = pd.to_numeric(df_catalog.get('popularity_score', pd.Series()), errors='coerce')\n",
    "    df_catalog['rating'] = pd.to_numeric(df_catalog.get('rating', pd.Series()), errors='coerce')\n",
    "\n",
    "    # Drop rows where both scores are NaN (optional)\n",
    "    df_catalog = df_catalog.dropna(subset=['popularity_score', 'rating'], how='all')\n",
    "\n",
    "    # Filter\n",
    "    filtered = df_catalog[\n",
    "        (df_catalog['popularity_score'] > 0.7) |\n",
    "        (df_catalog['rating'] > 4.0)\n",
    "    ].copy()\n",
    "\n",
    "    print(f\"‚úÖ Filtered down to {len(filtered):,} high-quality releases (from {len(df_catalog):,})\")\n",
    "\n",
    "    output_path = PROCESSED_DIR / 'filtered_catalog.csv'\n",
    "    filtered.to_csv(output_path, index=False)\n",
    "    print(f\"üìÅ Saved filtered catalog to '{output_path}'\")\n",
    "\n",
    "    return filtered\n",
    "\n",
    "# Run filtering\n",
    "filtered_catalog = filter_high_quality_releases(existing_catalog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547418d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - Integration and Final Enhanced Catalog\n",
    "\n",
    "def merge_enriched_catalog(df_catalog, df_artists, df_labels, df_masters, save_path):\n",
    "    print(\"Integrating enriched data into final catalog...\")\n",
    "\n",
    "    df = df_catalog.copy()\n",
    "\n",
    "    # Merge label info if present\n",
    "    if df_labels is not None:\n",
    "        if 'release_labels_label_id' in df.columns and 'label_id' in df_labels.columns:\n",
    "            df = df.merge(\n",
    "                df_labels[['label_id', 'label_name', 'contact_info', 'parent_label_id', 'profile', 'data_quality']],\n",
    "                left_on='release_labels_label_id',\n",
    "                right_on='label_id',\n",
    "                how='left'\n",
    "            )\n",
    "            print(f\"‚úÖ Merged label data: {len(df)} rows\")\n",
    "        else:\n",
    "            print(\"‚ùå Label merge keys missing, skipping label merge.\")\n",
    "    else:\n",
    "        print(\"‚ùå df_labels is None, skipping label merge.\")\n",
    "\n",
    "    # Merge artist info\n",
    "    if df_artists is not None and 'artists_artist_id' in df.columns:\n",
    "        df = df.merge(\n",
    "            df_artists[['artist_id', 'real_name', 'profile', 'quality_score']],\n",
    "            left_on='artists_artist_id',\n",
    "            right_on='artist_id',\n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"‚úÖ Merged artist data: {len(df)} rows\")\n",
    "    else:\n",
    "        print(\"‚ùå 'artists_artist_id' column missing in catalog, skipping artist merge.\")\n",
    "\n",
    "    # Merge master info\n",
    "    if df_masters is not None and 'releases_release_master_id' in df.columns:\n",
    "        df = df.merge(\n",
    "            df_masters[['master_id', 'original_year', 'main_release_id', 'num_versions', 'master_title']],\n",
    "            left_on='releases_release_master_id',\n",
    "            right_on='master_id',\n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"‚úÖ Merged master data: {len(df)} rows\")\n",
    "    else:\n",
    "        print(\"‚ùå 'releases_release_master_id' column missing in catalog, skipping master merge.\")\n",
    "\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"üìÅ Final enriched catalog saved to: {save_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Run integration\n",
    "final_catalog = merge_enriched_catalog(\n",
    "    filtered_catalog,\n",
    "    df_artists,\n",
    "    df_labels,\n",
    "    df_masters,\n",
    "    save_path=PROCESSED_DIR / 'final_enriched_catalog.csv'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
