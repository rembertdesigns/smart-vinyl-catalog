{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a47fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sprint 3: Scaling Up to Production Data\n",
      "==================================================\n",
      "Target: 100+ albums, realistic review data, advanced AI processing\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Sprint 3: Data Scaling & Real Dataset Integration\n",
    "## Smart Vinyl Catalog - Production Scale Implementation\n",
    "\n",
    "Moving from 5-album demo to production-scale catalog with real data sources.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Setup paths and imports\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.insert(0, os.path.join(project_root, 'src'))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join(project_root, '.env'))\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from config.bigquery_config import config\n",
    "\n",
    "client = config.get_client()\n",
    "\n",
    "print(\"Sprint 3: Scaling Up to Production Data\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Target: 100+ albums, realistic review data, advanced AI processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b94040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALING UP: Real Data Integration\n",
      "==================================================\n",
      "Kaggle download failed: Could not find kaggle.json. Make sure it's located in /Users/richpointofview/.kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n",
      "Creating larger sample dataset instead...\n",
      "Created expanded sample: 100 releases\n"
     ]
    }
   ],
   "source": [
    "# Download and process real Discogs data\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"SCALING UP: Real Data Integration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Download Discogs dataset from Kaggle\n",
    "# Note: You'll need Kaggle API credentials\n",
    "try:\n",
    "    import kaggle\n",
    "    \n",
    "    # Download Discogs data\n",
    "    kaggle.api.dataset_download_files(\n",
    "        'ofurkancoban/discogs-data-dumps-april-2025',\n",
    "        path='../data/raw/',\n",
    "        unzip=True\n",
    "    )\n",
    "    print(\"✅ Downloaded Discogs dataset\")\n",
    "    \n",
    "    # Process releases data\n",
    "    releases_df = pd.read_csv('../data/raw/discogs_releases.csv', nrows=10000)  # Sample first 10k\n",
    "    print(f\"Loaded {len(releases_df)} releases from Discogs\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Kaggle download failed: {e}\")\n",
    "    print(\"Creating larger sample dataset instead...\")\n",
    "    \n",
    "    # Create expanded sample data for demonstration\n",
    "    expanded_sample = []\n",
    "    genres = ['Jazz', 'Rock', 'Electronic', 'Folk', 'Soul', 'Funk']\n",
    "    labels = ['Blue Note', 'Columbia', 'Atlantic', 'Verve', 'Impulse!', 'ECM']\n",
    "    \n",
    "    for i in range(100):  # 100 albums instead of 5\n",
    "        expanded_sample.append({\n",
    "            'release_id': f'{200000 + i}',\n",
    "            'title': f'Sample Album {i+1}',\n",
    "            'artist': f'Artist {i%20}',  # 20 different artists\n",
    "            'year': 1950 + (i % 70),  # Span 1950-2020\n",
    "            'genre': genres[i % len(genres)],\n",
    "            'label': labels[i % len(labels)],\n",
    "            'country': 'US'\n",
    "        })\n",
    "    \n",
    "    releases_df = pd.DataFrame(expanded_sample)\n",
    "    print(f\"Created expanded sample: {len(releases_df)} releases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d729b0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Review Data...\n",
      "Generated 100 reviews\n"
     ]
    }
   ],
   "source": [
    "# Simulate processing MARD review data\n",
    "print(\"Processing Review Data...\")\n",
    "\n",
    "# In real implementation, download from MARD project\n",
    "# For now, generate realistic review data\n",
    "import random\n",
    "\n",
    "review_templates = [\n",
    "    \"A {adjective} {genre} album that {verb} the listener. The {instrument} work is {quality}.\",\n",
    "    \"This {year}s release {action} with {emotion}. {artist}'s {style} approach creates {atmosphere}.\",\n",
    "    \"Essential {genre} recording. The {aspect} demonstrates {quality} throughout.\"\n",
    "]\n",
    "\n",
    "adjectives = ['masterful', 'groundbreaking', 'contemplative', 'energetic', 'innovative']\n",
    "verbs = ['captivates', 'challenges', 'soothes', 'energizes', 'inspires'] \n",
    "instruments = ['saxophone', 'piano', 'trumpet', 'bass', 'drums']\n",
    "qualities = ['exceptional', 'outstanding', 'remarkable', 'sublime', 'brilliant']\n",
    "actions = ['resonates', 'connects', 'strikes a chord', 'makes an impression']\n",
    "emotions = ['deep emotion', 'raw energy', 'subtle beauty', 'complex feelings']\n",
    "styles = ['unique', 'traditional', 'experimental', 'refined', 'bold']\n",
    "atmospheres = ['an immersive experience', 'lasting impact', 'memorable moments']\n",
    "aspects = ['composition', 'performance', 'production', 'arrangement']\n",
    "\n",
    "expanded_reviews = []\n",
    "for i, album in releases_df.iterrows():\n",
    "    if i < 200:  # Generate reviews for subset\n",
    "        template = random.choice(review_templates)\n",
    "        review = template.format(\n",
    "            adjective=random.choice(adjectives),\n",
    "            genre=album['genre'].lower(),\n",
    "            verb=random.choice(verbs),\n",
    "            instrument=random.choice(instruments),\n",
    "            quality=random.choice(qualities),\n",
    "            year=str(album['year'])[:3] + '0',\n",
    "            action=random.choice(actions),\n",
    "            emotion=random.choice(emotions),\n",
    "            artist=album['artist'],\n",
    "            style=random.choice(styles),\n",
    "            atmosphere=random.choice(atmospheres),\n",
    "            aspect=random.choice(aspects)\n",
    "        )\n",
    "        \n",
    "        expanded_reviews.append({\n",
    "            'album_id': album['release_id'],\n",
    "            'album_title': album['title'],\n",
    "            'artist': album['artist'],\n",
    "            'review_text': review,\n",
    "            'rating': round(random.uniform(2.5, 5.0), 1),\n",
    "            'review_source': random.choice(['AllMusic', 'Rolling Stone', 'Pitchfork', 'DownBeat', 'JazzTimes'])\n",
    "        })\n",
    "\n",
    "reviews_df = pd.DataFrame(expanded_reviews)\n",
    "print(f\"Generated {len(reviews_df)} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877d6922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch 1: 100 rows to discogs_releases\n",
      "✅ Total uploaded: 100 rows to discogs_releases\n",
      "Uploaded batch 1: 100 rows to album_reviews\n",
      "✅ Total uploaded: 100 rows to album_reviews\n",
      "discogs_releases: 100 rows\n",
      "album_reviews: 100 rows\n"
     ]
    }
   ],
   "source": [
    "# Upload scaled dataset to BigQuery\n",
    "def upload_large_dataset(df, table_name, batch_size=1000):\n",
    "    \"\"\"Upload large dataset in batches\"\"\"\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        if i == 0:\n",
    "            # First batch - overwrite table\n",
    "            job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "        else:\n",
    "            # Subsequent batches - append\n",
    "            job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\")\n",
    "        \n",
    "        table_id = f\"{client.project}.vinyl_catalog.{table_name}\"\n",
    "        job = client.load_table_from_dataframe(batch, table_id, job_config=job_config)\n",
    "        job.result()\n",
    "        \n",
    "        print(f\"Uploaded batch {i//batch_size + 1}: {len(batch)} rows to {table_name}\")\n",
    "    \n",
    "    print(f\"✅ Total uploaded: {total_rows} rows to {table_name}\")\n",
    "\n",
    "# Upload scaled data\n",
    "upload_large_dataset(releases_df, 'discogs_releases')\n",
    "upload_large_dataset(reviews_df, 'album_reviews')\n",
    "\n",
    "# Verify scale\n",
    "for table in ['discogs_releases', 'album_reviews']:\n",
    "    count_query = f\"SELECT COUNT(*) as count FROM `vinyl_catalog.{table}`\"\n",
    "    result = client.query(count_query).to_dataframe()\n",
    "    print(f\"{table}: {result['count'].iloc[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d8f2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING SCALED SYSTEM\n",
      "========================================\n",
      "discogs_releases: 100 rows\n",
      "album_reviews: 100 rows\n",
      "\n",
      "GENRE ANALYSIS (Scaled Data):\n",
      "     genre  album_count  avg_rating  earliest_year  latest_year\n",
      "Electronic           17    3.811765           1952         2018\n",
      "      Jazz           17    3.717647           1950         2016\n",
      "      Rock           17    3.805882           1951         2017\n",
      "      Folk           17    3.941176           1953         2019\n",
      "      Funk           16    3.725000           1951         2015\n",
      "      Soul           16    3.581250           1950         2014\n",
      "\n",
      "TOP LABELS:\n",
      "    label  releases  avg_rating\n",
      "    Verve        17         3.9\n",
      " Atlantic        17         3.8\n",
      "Blue Note        17         3.7\n",
      " Columbia        17         3.8\n",
      "      ECM        16         3.7\n",
      " Impulse!        16         3.6\n",
      "\n",
      "System now operates at realistic scale:\n",
      "- 100 album catalog\n",
      "- 100 reviews\n",
      "- Multi-genre, multi-decade coverage\n",
      "- Ready for advanced AI processing\n"
     ]
    }
   ],
   "source": [
    "# Test the scaled data system\n",
    "print(\"TESTING SCALED SYSTEM\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Verify data scale\n",
    "tables_info = {}\n",
    "for table in ['discogs_releases', 'album_reviews']:\n",
    "    count_query = f\"SELECT COUNT(*) as count FROM `vinyl_catalog.{table}`\"\n",
    "    result = client.query(count_query).to_dataframe()\n",
    "    tables_info[table] = result['count'].iloc[0]\n",
    "    print(f\"{table}: {result['count'].iloc[0]} rows\")\n",
    "\n",
    "# Test complex queries with scaled data\n",
    "genre_analysis_query = \"\"\"\n",
    "SELECT \n",
    "    dr.genre,\n",
    "    COUNT(*) as album_count,\n",
    "    AVG(ar.rating) as avg_rating,\n",
    "    MIN(dr.year) as earliest_year,\n",
    "    MAX(dr.year) as latest_year\n",
    "FROM `vinyl_catalog.discogs_releases` dr\n",
    "JOIN `vinyl_catalog.album_reviews` ar ON dr.release_id = ar.album_id\n",
    "GROUP BY dr.genre\n",
    "ORDER BY album_count DESC\n",
    "\"\"\"\n",
    "\n",
    "genre_data = client.query(genre_analysis_query).to_dataframe()\n",
    "print(\"\\nGENRE ANALYSIS (Scaled Data):\")\n",
    "print(genre_data.to_string(index=False))\n",
    "\n",
    "# Label distribution\n",
    "label_query = \"\"\"\n",
    "SELECT \n",
    "    label,\n",
    "    COUNT(*) as releases,\n",
    "    ROUND(AVG(ar.rating), 1) as avg_rating\n",
    "FROM `vinyl_catalog.discogs_releases` dr\n",
    "JOIN `vinyl_catalog.album_reviews` ar ON dr.release_id = ar.album_id\n",
    "GROUP BY label\n",
    "ORDER BY releases DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "label_data = client.query(label_query).to_dataframe()\n",
    "print(f\"\\nTOP LABELS:\")\n",
    "print(label_data.to_string(index=False))\n",
    "\n",
    "print(f\"\\nSystem now operates at realistic scale:\")\n",
    "print(f\"- {tables_info['discogs_releases']} album catalog\")\n",
    "print(f\"- {tables_info['album_reviews']} reviews\")\n",
    "print(f\"- Multi-genre, multi-decade coverage\")\n",
    "print(f\"- Ready for advanced AI processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d24d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AI functions with scaled dataset\n",
    "print(\"TESTING AI FUNCTIONS WITH SCALED DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test AI.GENERATE with album categorization\n",
    "categorization_test = \"\"\"\n",
    "SELECT \n",
    "    title,\n",
    "    artist,\n",
    "    genre,\n",
    "    AI.GENERATE(\n",
    "        'Categorize this album by mood in one word - contemplative, energetic, or experimental: ' \n",
    "        || title || ' by ' || artist || ' (' || genre || ')'\n",
    "    ) as ai_mood\n",
    "FROM `vinyl_catalog.discogs_releases`\n",
    "WHERE genre IN ('Jazz', 'Rock', 'Electronic')\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = client.query(categorization_test).to_dataframe()\n",
    "    print(\"✅ AI categorization working!\")\n",
    "    print(result.to_string(index=False))\n",
    "    ai_ready = True\n",
    "except Exception as e:\n",
    "    print(f\"AI functions status: {e}\")\n",
    "    ai_ready = False\n",
    "\n",
    "# Test recommendation generation if AI is ready\n",
    "if ai_ready:\n",
    "    recommendation_test = \"\"\"\n",
    "    SELECT AI.GENERATE(\n",
    "        'Based on these highly-rated albums: Kind of Blue (Jazz), A Love Supreme (Jazz), recommend 3 similar albums with brief explanations'\n",
    "    ) as recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        rec_result = client.query(recommendation_test).to_dataframe()\n",
    "        print(f\"\\n🎵 AI RECOMMENDATIONS:\")\n",
    "        print(rec_result['recommendations'].iloc[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Recommendation test: {e}\")\n",
    "\n",
    "print(f\"\\nAI Status: {'Active - proceeding with advanced features' if ai_ready else 'Still activating - implementing fallback system'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
