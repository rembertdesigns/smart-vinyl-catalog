{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7955da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import requests\n",
    "import time\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageFilter\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pickle\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class ImageFeatures:\n",
    "    \"\"\"Container for extracted image features\"\"\"\n",
    "    image_id: str\n",
    "    color_histogram: np.ndarray\n",
    "    texture_features: np.ndarray\n",
    "    edge_features: np.ndarray\n",
    "    dominant_colors: List[Tuple[int, int, int]]\n",
    "    brightness: float\n",
    "    contrast: float\n",
    "    saturation: float\n",
    "    complexity_score: float\n",
    "    \n",
    "class AlbumCoverAnalyzer:\n",
    "    \"\"\"Advanced computer vision analysis for album covers\"\"\"\n",
    "    \n",
    "    def __init__(self, target_size: Tuple[int, int] = (224, 224)):\n",
    "        self.target_size = target_size\n",
    "        \n",
    "    def extract_color_features(self, image: Image.Image) -> Tuple[np.ndarray, List[Tuple[int, int, int]]]:\n",
    "        \"\"\"Extract color histogram and dominant colors\"\"\"\n",
    "        # Convert to RGB if needed\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # Resize for consistent analysis\n",
    "        image_resized = image.resize(self.target_size)\n",
    "        img_array = np.array(image_resized)\n",
    "        \n",
    "        # Color histogram (8 bins per channel)\n",
    "        hist_r = np.histogram(img_array[:,:,0], bins=8, range=(0, 256))[0]\n",
    "        hist_g = np.histogram(img_array[:,:,1], bins=8, range=(0, 256))[0]\n",
    "        hist_b = np.histogram(img_array[:,:,2], bins=8, range=(0, 256))[0]\n",
    "        color_hist = np.concatenate([hist_r, hist_g, hist_b])\n",
    "        color_hist = color_hist / np.sum(color_hist)  # Normalize\n",
    "        \n",
    "        # Dominant colors using K-means\n",
    "        pixels = img_array.reshape(-1, 3)\n",
    "        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "        kmeans.fit(pixels)\n",
    "        dominant_colors = [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]\n",
    "        \n",
    "        return color_hist, dominant_colors\n",
    "    \n",
    "    def extract_texture_features(self, image: Image.Image) -> np.ndarray:\n",
    "        \"\"\"Extract texture features using Local Binary Patterns approximation\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = image.convert('L').resize(self.target_size)\n",
    "        gray_array = np.array(gray)\n",
    "        \n",
    "        # Simple texture analysis using gradient magnitudes\n",
    "        # Calculate gradients\n",
    "        grad_x = cv2.Sobel(gray_array, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(gray_array, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        \n",
    "        # Texture histogram (16 bins)\n",
    "        texture_hist = np.histogram(magnitude, bins=16, range=(0, 255))[0]\n",
    "        texture_hist = texture_hist / np.sum(texture_hist)  # Normalize\n",
    "        \n",
    "        # Additional texture measures\n",
    "        variance = np.var(gray_array)\n",
    "        mean_gradient = np.mean(magnitude)\n",
    "        \n",
    "        return np.concatenate([texture_hist, [variance / 1000, mean_gradient / 100]])\n",
    "    \n",
    "    def extract_edge_features(self, image: Image.Image) -> np.ndarray:\n",
    "        \"\"\"Extract edge-based features\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = image.convert('L').resize(self.target_size)\n",
    "        gray_array = np.array(gray)\n",
    "        \n",
    "        # Canny edge detection\n",
    "        edges = cv2.Canny(gray_array, 50, 150)\n",
    "        \n",
    "        # Edge density and distribution\n",
    "        edge_density = np.sum(edges > 0) / edges.size\n",
    "        \n",
    "        # Edge direction histogram\n",
    "        grad_x = cv2.Sobel(gray_array, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(gray_array, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        angles = np.arctan2(grad_y, grad_x)\n",
    "        angle_hist = np.histogram(angles, bins=8, range=(-np.pi, np.pi))[0]\n",
    "        angle_hist = angle_hist / np.sum(angle_hist) if np.sum(angle_hist) > 0 else angle_hist\n",
    "        \n",
    "        return np.concatenate([angle_hist, [edge_density]])\n",
    "    \n",
    "    def extract_global_features(self, image: Image.Image) -> Tuple[float, float, float, float]:\n",
    "        \"\"\"Extract global image properties\"\"\"\n",
    "        # Convert to different color spaces\n",
    "        rgb_img = image.convert('RGB').resize(self.target_size)\n",
    "        hsv_img = rgb_img.convert('HSV')\n",
    "        \n",
    "        rgb_array = np.array(rgb_img)\n",
    "        hsv_array = np.array(hsv_img)\n",
    "        \n",
    "        # Brightness (average luminance)\n",
    "        brightness = np.mean(rgb_array)\n",
    "        \n",
    "        # Contrast (standard deviation of luminance)\n",
    "        gray = np.mean(rgb_array, axis=2)\n",
    "        contrast = np.std(gray)\n",
    "        \n",
    "        # Saturation (average saturation in HSV)\n",
    "        saturation = np.mean(hsv_array[:,:,1])\n",
    "        \n",
    "        # Complexity (edge density + color variance)\n",
    "        edges = cv2.Canny(gray.astype(np.uint8), 50, 150)\n",
    "        edge_density = np.sum(edges > 0) / edges.size\n",
    "        color_variance = np.var(rgb_array.reshape(-1, 3), axis=0).mean()\n",
    "        complexity_score = edge_density + (color_variance / 1000)\n",
    "        \n",
    "        return brightness, contrast, saturation, complexity_score\n",
    "    \n",
    "    def analyze_image(self, image: Image.Image, image_id: str) -> ImageFeatures:\n",
    "        \"\"\"Complete feature extraction pipeline\"\"\"\n",
    "        try:\n",
    "            # Extract all feature types\n",
    "            color_hist, dominant_colors = self.extract_color_features(image)\n",
    "            texture_features = self.extract_texture_features(image)\n",
    "            edge_features = self.extract_edge_features(image)\n",
    "            brightness, contrast, saturation, complexity = self.extract_global_features(image)\n",
    "            \n",
    "            return ImageFeatures(\n",
    "                image_id=image_id,\n",
    "                color_histogram=color_hist,\n",
    "                texture_features=texture_features,\n",
    "                edge_features=edge_features,\n",
    "                dominant_colors=dominant_colors,\n",
    "                brightness=brightness,\n",
    "                contrast=contrast,\n",
    "                saturation=saturation,\n",
    "                complexity_score=complexity\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to analyze image {image_id}: {e}\")\n",
    "            # Return default features\n",
    "            return ImageFeatures(\n",
    "                image_id=image_id,\n",
    "                color_histogram=np.zeros(24),\n",
    "                texture_features=np.zeros(18),\n",
    "                edge_features=np.zeros(9),\n",
    "                dominant_colors=[(0, 0, 0)] * 5,\n",
    "                brightness=0.0,\n",
    "                contrast=0.0,\n",
    "                saturation=0.0,\n",
    "                complexity_score=0.0\n",
    "            )\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = AlbumCoverAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab711310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating actual data structure...\n",
      "Available columns in releases table: ['release_id', 'discogs_id', 'title', 'artist', 'album', 'year', 'genre', 'label', 'country', 'format', 'status', 'catalog_number', 'master_id', 'popularity_score', 'rating', 'plays', 'favorites', 'duration', 'data_quality', 'source', 'created_at', 'updated_at']\n",
      "\n",
      "Sample data (first 3 records):\n",
      "Record 1:\n",
      "  release_id: 1\n",
      "  title: Tentacle Hentaij - Core Noisetone\n",
      "  artist: Ralph Brown\n",
      "  album: Spettro Records Volume 2 - Decline\n",
      "  year: 2015\n",
      "  genre: Experimental\n",
      "  label: FMA\n",
      "  country: US\n",
      "  format: Unknown\n",
      "  status: Unknown\n",
      "  catalog_number: Unknown\n",
      "  popularity_score: 0.0002024291497975\n",
      "  rating: 2.0\n",
      "  plays: 0\n",
      "  favorites: 1\n",
      "  duration: 265\n",
      "  data_quality: Unknown\n",
      "  source: fma_data\n",
      "  created_at: 2025-09-04 00:41:16\n",
      "  updated_at: 2025-09-04 00:41:16\n",
      "Record 2:\n",
      "  release_id: 2\n",
      "  title: Goldfish\n",
      "  artist: Aoiroooasamusi\n",
      "  album: Root Of Sorrow\n",
      "  year: 2010\n",
      "  genre: Unknown\n",
      "  label: FMA\n",
      "  country: US\n",
      "  format: Unknown\n",
      "  status: Unknown\n",
      "  catalog_number: Unknown\n",
      "  popularity_score: 0.0034412955465587\n",
      "  rating: 2.0\n",
      "  plays: 0\n",
      "  favorites: 17\n",
      "  duration: 308\n",
      "  data_quality: Unknown\n",
      "  source: fma_data\n",
      "  created_at: 2025-09-04 00:41:16\n",
      "  updated_at: 2025-09-04 00:41:16\n",
      "Record 3:\n",
      "  release_id: 3\n",
      "  title: The Monk Said\n",
      "  artist: dmyra\n",
      "  album: Love in the Air\n",
      "  year: 2009\n",
      "  genre: Unknown\n",
      "  label: FMA\n",
      "  country: US\n",
      "  format: Unknown\n",
      "  status: Unknown\n",
      "  catalog_number: Unknown\n",
      "  popularity_score: 0.0008097165991902\n",
      "  rating: 2.0\n",
      "  plays: 0\n",
      "  favorites: 4\n",
      "  duration: 388\n",
      "  data_quality: Unknown\n",
      "  source: fma_data\n",
      "  created_at: 2025-09-04 00:41:16\n",
      "  updated_at: 2025-09-04 00:41:16\n",
      "\n",
      "Checking potential identifiers:\n",
      "  release_id: 55000 non-null values\n",
      "  discogs_id: 0 non-null values\n",
      "  title: 55000 non-null values\n",
      "  artist: 55000 non-null values\n",
      "\n",
      "============================================================\n",
      "CREATING COVERS WITH FLEXIBLE APPROACH\n",
      "============================================================\n",
      "Found 100 releases to create covers for\n",
      "Failed to create cover for '11 strANGE Ls': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Lips': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'nostalgia of an ex-gangsta-rapper': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'The Tea Party': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Summer Spliffs': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Steppin': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Realness': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'One Fine Day': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Together In The Empty': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'UP': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Throughout The City': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for '12 MORNINGS': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Wild Things (Instrumental)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Love Of My Life': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Presenterator': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for '5:00 AM': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Pick Up a Convict on Alcatraz': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'What Circle Where': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Take Care': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Tom's Lullaby (with Les Gauchers Orchestra)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Triumph': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Unexpected Hoedown In Bagging Area': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'AUTUMN SUNSET': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Thursday & Snow (Reprise)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Double Horse': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Tripped & Fell In Love (instrumental)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Instrumental #2 Revisited': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Druids March': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'VHS': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Silver': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Emergency Exit': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Ends': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Q': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Quincas': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Rio': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Ear Conflict on Main Street': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Look at You, You're Ugly': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Ants': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'El Cha Cha Man': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'all these wires between us': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Mid Day Blues': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Just Had To Let You Know': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Gonna Make It Through This Year': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Laceration': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Golden Hour': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Sweet Water': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Lontana, dolcemente sospesa': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Desconocido': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'The Machine That Won The War': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Brunch Club (extended edition)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Stin Ypoga': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Polaroid': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Amor (com Mr V.R.)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Preludes No. 1 & 2': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Real Swing Shet': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Bughici - Suite for Violin, 9 Hora, vivace': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Blind Eyes': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Horse Steppin'': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Foolin' Around Mix (Instrumental)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Lovely, Lonely (Instrumental)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Shanghai Reggae (DJ Side's Alternate Take)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'The Factory': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'CPU Talk': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Stronger Living Feat Wordsmith': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Strings And Blips': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Solitude': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Gotta Keep Moving': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Siam Soo': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Star-spangled banner (Song)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Circle Round': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'watashi': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Ogyama Abere': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Prelude No. 5': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Mirando Hacia Atrás': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'The 3rd': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Smiling Flowers': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'redRum': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Prologue': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Andante from Italian Concerto, BWV 971 (Bach)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Raag (Youtube)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Lovers Like Neon': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Trees Don't Sleep': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for '60's Quiz Show': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Tasky': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Lately (Deuxième)': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for 'Shaman's Roar': UNIQUE constraint failed: album_covers.image_hash\n",
      "Failed to create cover for '1911 - Naughty Marietta': UNIQUE constraint failed: album_covers.image_hash\n",
      "\n",
      "Successfully created 13 album covers!\n",
      "Verification:\n",
      "  Covers in database: 13\n",
      "  Cover files on disk: 100\n",
      "\n",
      "✅ SUCCESS! Created 13 album covers\n",
      "📁 Covers saved to: /Users/richpointofview/smart-vinyl-catalog/data/album_covers\n",
      "\n",
      "Now you can re-run Cell 3 from the main notebook to extract visual features!\n",
      "\n",
      "Sample covers created:\n",
      "  • alright lover - Snow Wave (2011) [Pop]\n",
      "    File: cover_release_207.png\n",
      "  • Bitbasic - Be careful, I've Stood On It Too (2012) [Electronic]\n",
      "    File: cover_release_846.png\n",
      "  • Lovira - All things considered (2012) [Classical]\n",
      "    File: cover_release_1291.png\n",
      "  • Latché Swing - Menilmontant (2008) [Jazz]\n",
      "    File: cover_release_2060.png\n",
      "  • Jahzzar - Take Me Higher (None) [Unknown]\n",
      "    File: cover_release_2433.png\n"
     ]
    }
   ],
   "source": [
    "# Fixed Cover Generation - Adapts to Your Actual Data Structure\n",
    "\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DB_PATH = DATA_DIR / 'database' / 'vinyl_catalog.db'\n",
    "COVERS_DIR = DATA_DIR / 'album_covers'\n",
    "\n",
    "print(\"Investigating actual data structure...\")\n",
    "\n",
    "# First, let's see what columns actually exist\n",
    "with sqlite3.connect(str(DB_PATH)) as conn:\n",
    "    cursor = conn.execute(\"PRAGMA table_info(releases)\")\n",
    "    columns = [row[1] for row in cursor.fetchall()]\n",
    "    print(f\"Available columns in releases table: {columns}\")\n",
    "    \n",
    "    # Get a sample of actual data to see what we're working with\n",
    "    cursor = conn.execute(\"SELECT * FROM releases LIMIT 3\")\n",
    "    sample_data = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\nSample data (first 3 records):\")\n",
    "    for i, row in enumerate(sample_data):\n",
    "        print(f\"Record {i+1}:\")\n",
    "        for j, col in enumerate(columns):\n",
    "            if row[j] is not None:\n",
    "                print(f\"  {col}: {row[j]}\")\n",
    "    \n",
    "    # Check what could serve as unique identifiers\n",
    "    print(f\"\\nChecking potential identifiers:\")\n",
    "    \n",
    "    # Check for non-null values in key columns\n",
    "    key_columns = ['release_id', 'discogs_id', 'title', 'artist']\n",
    "    for col in key_columns:\n",
    "        if col in columns:\n",
    "            cursor = conn.execute(f\"SELECT COUNT(*) FROM releases WHERE {col} IS NOT NULL\")\n",
    "            count = cursor.fetchone()[0]\n",
    "            print(f\"  {col}: {count} non-null values\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"CREATING COVERS WITH FLEXIBLE APPROACH\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "def create_genre_based_cover(release_info):\n",
    "    \"\"\"Create a cover based on available release information\"\"\"\n",
    "    size = (300, 300)\n",
    "    \n",
    "    # Genre-based color palettes\n",
    "    genre_colors = {\n",
    "        'rock': [(220, 50, 50), (180, 40, 40), (140, 30, 30)],\n",
    "        'pop': [(255, 20, 147), (200, 15, 110), (150, 10, 80)],\n",
    "        'jazz': [(50, 100, 150), (40, 80, 120), (30, 60, 90)],\n",
    "        'electronic': [(100, 255, 100), (70, 200, 70), (40, 150, 40)],\n",
    "        'classical': [(128, 0, 128), (100, 0, 100), (70, 0, 70)],\n",
    "        'hip hop': [(255, 215, 0), (200, 170, 0), (150, 120, 0)],\n",
    "        'country': [(139, 69, 19), (110, 55, 15), (80, 40, 10)],\n",
    "        'folk': [(34, 139, 34), (25, 100, 25), (15, 70, 15)],\n",
    "        'blues': [(0, 0, 139), (0, 0, 100), (0, 0, 70)],\n",
    "        'reggae': [(255, 255, 0), (200, 200, 0), (150, 150, 0)],\n",
    "    }\n",
    "    \n",
    "    # Default colors for unknown genres\n",
    "    default_colors = [(100, 100, 100), (70, 70, 70), (40, 40, 40)]\n",
    "    \n",
    "    # Get genre and normalize it\n",
    "    genre = str(release_info.get('genre', 'unknown')).lower().strip()\n",
    "    colors = genre_colors.get(genre, default_colors)\n",
    "    \n",
    "    # Find closest match for partial genre names\n",
    "    if colors == default_colors and genre != 'unknown':\n",
    "        for known_genre, palette in genre_colors.items():\n",
    "            if known_genre in genre or genre in known_genre:\n",
    "                colors = palette\n",
    "                break\n",
    "    \n",
    "    # Create image\n",
    "    img = Image.new('RGB', size, color=colors[2])\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Create gradient background\n",
    "    center_x, center_y = size[0] // 2, size[1] // 2\n",
    "    max_radius = min(center_x, center_y)\n",
    "    \n",
    "    for y in range(size[1]):\n",
    "        for x in range(size[0]):\n",
    "            # Distance from center\n",
    "            dx, dy = x - center_x, y - center_y\n",
    "            distance = (dx*dx + dy*dy) ** 0.5\n",
    "            \n",
    "            # Normalize distance (0 to 1)\n",
    "            norm_dist = min(distance / max_radius, 1.0)\n",
    "            \n",
    "            # Interpolate between colors\n",
    "            if norm_dist < 0.5:\n",
    "                # Blend between color[0] and color[1]\n",
    "                blend = norm_dist * 2\n",
    "                color = tuple(\n",
    "                    int(colors[0][i] * (1-blend) + colors[1][i] * blend)\n",
    "                    for i in range(3)\n",
    "                )\n",
    "            else:\n",
    "                # Blend between color[1] and color[2]\n",
    "                blend = (norm_dist - 0.5) * 2\n",
    "                color = tuple(\n",
    "                    int(colors[1][i] * (1-blend) + colors[2][i] * blend)\n",
    "                    for i in range(3)\n",
    "                )\n",
    "            \n",
    "            draw.point((x, y), fill=color)\n",
    "    \n",
    "    # Add decorative elements based on year\n",
    "    year = release_info.get('year')\n",
    "    if year:\n",
    "        try:\n",
    "            year = int(year)\n",
    "            if year < 1970:\n",
    "                # Vintage style - concentric circles\n",
    "                for i in range(3):\n",
    "                    radius = 30 + i * 20\n",
    "                    draw.ellipse([center_x-radius, center_y-radius, \n",
    "                                center_x+radius, center_y+radius], \n",
    "                               outline=colors[0], width=2)\n",
    "            elif year >= 1970 and year < 1990:\n",
    "                # 70s-80s style - geometric shapes\n",
    "                draw.polygon([center_x, center_y-50, center_x+50, center_y+50, \n",
    "                            center_x-50, center_y+50], outline=colors[0], width=3)\n",
    "            elif year >= 1990 and year < 2010:\n",
    "                # 90s-2000s style - rectangles\n",
    "                draw.rectangle([center_x-60, center_y-40, center_x+60, center_y+40], \n",
    "                             outline=colors[0], width=2)\n",
    "            else:\n",
    "                # Modern style - minimalist line\n",
    "                draw.line([50, center_y, size[0]-50, center_y], fill=colors[0], width=4)\n",
    "        except (ValueError, TypeError):\n",
    "            pass  # Skip year-based decoration if year is not a valid number\n",
    "    \n",
    "    return img\n",
    "\n",
    "def generate_covers_flexible():\n",
    "    \"\"\"Generate covers using whatever data is available\"\"\"\n",
    "    COVERS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with sqlite3.connect(str(DB_PATH)) as conn:\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        \n",
    "        # Use flexible query - don't require discogs_id\n",
    "        cursor = conn.execute(\"\"\"\n",
    "            SELECT release_id, title, artist, album, year, genre, \n",
    "                   popularity_score, rating, discogs_id\n",
    "            FROM releases \n",
    "            WHERE title IS NOT NULL AND artist IS NOT NULL\n",
    "            ORDER BY CASE \n",
    "                WHEN popularity_score IS NOT NULL THEN popularity_score \n",
    "                ELSE 0 \n",
    "            END DESC,\n",
    "            CASE \n",
    "                WHEN rating IS NOT NULL THEN rating \n",
    "                ELSE 0 \n",
    "            END DESC\n",
    "            LIMIT 100\n",
    "        \"\"\")\n",
    "        \n",
    "        releases = [dict(row) for row in cursor.fetchall()]\n",
    "        print(f\"Found {len(releases)} releases to create covers for\")\n",
    "        \n",
    "        covers_created = 0\n",
    "        for release in releases:\n",
    "            try:\n",
    "                # Create the cover\n",
    "                cover_image = create_genre_based_cover(release)\n",
    "                \n",
    "                # Generate filename using available identifiers\n",
    "                if release['discogs_id']:\n",
    "                    filename = f\"cover_discogs_{release['discogs_id']}.png\"\n",
    "                else:\n",
    "                    filename = f\"cover_release_{release['release_id']}.png\"\n",
    "                \n",
    "                cover_path = COVERS_DIR / filename\n",
    "                cover_image.save(cover_path)\n",
    "                \n",
    "                # Calculate hash\n",
    "                image_hash = hashlib.md5(cover_image.tobytes()).hexdigest()\n",
    "                \n",
    "                # Store in database\n",
    "                cursor = conn.execute(\"\"\"\n",
    "                    INSERT INTO album_covers \n",
    "                    (release_id, discogs_id, local_path, image_hash, width, height, file_size)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "                \"\"\", (\n",
    "                    release['release_id'],\n",
    "                    release['discogs_id'],\n",
    "                    str(cover_path),\n",
    "                    image_hash,\n",
    "                    cover_image.width,\n",
    "                    cover_image.height,\n",
    "                    cover_path.stat().st_size if cover_path.exists() else 0\n",
    "                ))\n",
    "                \n",
    "                covers_created += 1\n",
    "                \n",
    "                if covers_created % 20 == 0:\n",
    "                    print(f\"Created {covers_created} covers...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to create cover for '{release['title']}': {e}\")\n",
    "                continue\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"\\nSuccessfully created {covers_created} album covers!\")\n",
    "        \n",
    "        # Verify covers were created\n",
    "        cursor = conn.execute(\"SELECT COUNT(*) FROM album_covers WHERE local_path IS NOT NULL\")\n",
    "        db_cover_count = cursor.fetchone()[0]\n",
    "        \n",
    "        file_cover_count = len(list(COVERS_DIR.glob(\"*.png\")))\n",
    "        \n",
    "        print(f\"Verification:\")\n",
    "        print(f\"  Covers in database: {db_cover_count}\")\n",
    "        print(f\"  Cover files on disk: {file_cover_count}\")\n",
    "        \n",
    "        return covers_created\n",
    "\n",
    "# Run the improved cover generation\n",
    "covers_created = generate_covers_flexible()\n",
    "\n",
    "if covers_created > 0:\n",
    "    print(f\"\\n✅ SUCCESS! Created {covers_created} album covers\")\n",
    "    print(f\"📁 Covers saved to: {COVERS_DIR}\")\n",
    "    print(f\"\\nNow you can re-run Cell 3 from the main notebook to extract visual features!\")\n",
    "    \n",
    "    # Show a sample of what was created\n",
    "    print(f\"\\nSample covers created:\")\n",
    "    with sqlite3.connect(str(DB_PATH)) as conn:\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cursor = conn.execute(\"\"\"\n",
    "            SELECT r.artist, r.title, r.genre, r.year, ac.local_path\n",
    "            FROM album_covers ac\n",
    "            JOIN releases r ON ac.release_id = r.release_id\n",
    "            LIMIT 5\n",
    "        \"\"\")\n",
    "        \n",
    "        for row in cursor.fetchall():\n",
    "            print(f\"  • {row['artist']} - {row['title']} ({row['year']}) [{row['genre']}]\")\n",
    "            print(f\"    File: {Path(row['local_path']).name}\")\n",
    "else:\n",
    "    print(f\"\\n❌ Still no covers created. Let's check what's in the releases table:\")\n",
    "    \n",
    "    with sqlite3.connect(str(DB_PATH)) as conn:\n",
    "        cursor = conn.execute(\"\"\"\n",
    "            SELECT COUNT(*) as total,\n",
    "                   COUNT(CASE WHEN title IS NOT NULL THEN 1 END) as has_title,\n",
    "                   COUNT(CASE WHEN artist IS NOT NULL THEN 1 END) as has_artist,\n",
    "                   COUNT(CASE WHEN genre IS NOT NULL THEN 1 END) as has_genre\n",
    "            FROM releases\n",
    "        \"\"\")\n",
    "        \n",
    "        stats = cursor.fetchone()\n",
    "        print(f\"  Total releases: {stats[0]}\")\n",
    "        print(f\"  With title: {stats[1]}\")\n",
    "        print(f\"  With artist: {stats[2]}\")  \n",
    "        print(f\"  With genre: {stats[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ba8f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:34:35,851 - INFO - Processing features for 13 covers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting visual features from album covers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:34:37,314 - INFO - Extracted features for 10 covers...\n",
      "2025-09-03 21:34:37,909 - INFO - Feature extraction complete: 13 covers processed\n",
      "2025-09-03 21:34:37,917 - INFO - Stored similarity data for 13 covers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing visual similarities...\n",
      "Visual similarity computation complete!\n",
      "Feature vectors created for 13 album covers\n",
      "Similarity matrix shape: (13, 13)\n",
      "Ready for visual discovery!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - Feature Extraction and Similarity Computation\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from contextlib import contextmanager\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class VisualSimilarityEngine:\n",
    "    \"\"\"Compute visual similarities between album covers\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: Path, analyzer):\n",
    "        self.db_path = db_path\n",
    "        self.analyzer = analyzer\n",
    "        \n",
    "    @contextmanager\n",
    "    def get_db_connection(self):\n",
    "        \"\"\"Database connection context manager\"\"\"\n",
    "        conn = sqlite3.connect(str(self.db_path))\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        try:\n",
    "            yield conn\n",
    "        finally:\n",
    "            conn.close()\n",
    "    \n",
    "    def extract_features_for_all_covers(self) -> int:\n",
    "        \"\"\"Extract visual features for all album covers\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            # Get all covers that don't have features yet\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT ac.cover_id, ac.local_path, ac.release_id\n",
    "                FROM album_covers ac\n",
    "                LEFT JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                WHERE vf.feature_id IS NULL AND ac.local_path IS NOT NULL\n",
    "            \"\"\")\n",
    "            \n",
    "            covers_to_process = [dict(row) for row in cursor.fetchall()]\n",
    "        \n",
    "        logger.info(f\"Processing features for {len(covers_to_process)} covers...\")\n",
    "        features_extracted = 0\n",
    "        \n",
    "        for cover in covers_to_process:\n",
    "            try:\n",
    "                # Load and analyze image\n",
    "                image_path = Path(cover['local_path'])\n",
    "                if not image_path.exists():\n",
    "                    logger.warning(f\"Image file not found: {image_path}\")\n",
    "                    continue\n",
    "                    \n",
    "                image = Image.open(image_path)\n",
    "                features = self.analyzer.analyze_image(image, str(cover['cover_id']))\n",
    "                \n",
    "                # Store features in database\n",
    "                self.store_visual_features(cover['cover_id'], features)\n",
    "                features_extracted += 1\n",
    "                \n",
    "                if features_extracted % 10 == 0:\n",
    "                    logger.info(f\"Extracted features for {features_extracted} covers...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to extract features for cover {cover['cover_id']}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"Feature extraction complete: {features_extracted} covers processed\")\n",
    "        return features_extracted\n",
    "    \n",
    "    def store_visual_features(self, cover_id: int, features):\n",
    "        \"\"\"Store visual features in database\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            conn.execute(\"\"\"\n",
    "                INSERT OR REPLACE INTO visual_features \n",
    "                (cover_id, color_histogram, texture_features, edge_features, \n",
    "                 dominant_colors, brightness, contrast_score, saturation, complexity_score)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (\n",
    "                cover_id,\n",
    "                json.dumps(features.color_histogram.tolist()),\n",
    "                json.dumps(features.texture_features.tolist()),\n",
    "                json.dumps(features.edge_features.tolist()),\n",
    "                json.dumps(features.dominant_colors),\n",
    "                features.brightness,\n",
    "                features.contrast,\n",
    "                features.saturation,\n",
    "                features.complexity_score\n",
    "            ))\n",
    "            conn.commit()\n",
    "    \n",
    "    def compute_similarity_matrix(self) -> np.ndarray:\n",
    "        \"\"\"Compute similarity matrix for all covers\"\"\"\n",
    "        # Load all features\n",
    "        feature_data = self.load_all_features()\n",
    "        \n",
    "        if len(feature_data) < 2:\n",
    "            logger.warning(\"Not enough covers with features for similarity computation\")\n",
    "            return np.array([])\n",
    "        \n",
    "        # Combine all feature types into feature vectors\n",
    "        feature_vectors = []\n",
    "        cover_ids = []\n",
    "        \n",
    "        for cover_id, features in feature_data.items():\n",
    "            # Combine color, texture, and edge features\n",
    "            combined_features = np.concatenate([\n",
    "                features['color_histogram'],\n",
    "                features['texture_features'],\n",
    "                features['edge_features'],\n",
    "                [features['brightness'] / 255, features['contrast_score'] / 100, \n",
    "                 features['saturation'] / 255, features['complexity_score']]\n",
    "            ])\n",
    "            \n",
    "            feature_vectors.append(combined_features)\n",
    "            cover_ids.append(cover_id)\n",
    "        \n",
    "        # Convert to numpy array and compute similarities\n",
    "        feature_matrix = np.array(feature_vectors)\n",
    "        similarity_matrix = cosine_similarity(feature_matrix)\n",
    "        \n",
    "        # Store similarities in database\n",
    "        self.store_similarity_matrix(cover_ids, similarity_matrix)\n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    def load_all_features(self) -> dict:\n",
    "        \"\"\"Load all visual features from database\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    cover_id, color_histogram, texture_features, edge_features,\n",
    "                    dominant_colors, brightness, contrast_score, saturation, complexity_score\n",
    "                FROM visual_features\n",
    "            \"\"\")\n",
    "            \n",
    "            feature_data = {}\n",
    "            for row in cursor.fetchall():\n",
    "                try:\n",
    "                    feature_data[row['cover_id']] = {\n",
    "                        'color_histogram': np.array(json.loads(row['color_histogram'])),\n",
    "                        'texture_features': np.array(json.loads(row['texture_features'])),\n",
    "                        'edge_features': np.array(json.loads(row['edge_features'])),\n",
    "                        'dominant_colors': json.loads(row['dominant_colors']),\n",
    "                        'brightness': row['brightness'],\n",
    "                        'contrast_score': row['contrast_score'],\n",
    "                        'saturation': row['saturation'],\n",
    "                        'complexity_score': row['complexity_score']\n",
    "                    }\n",
    "                except (json.JSONDecodeError, TypeError) as e:\n",
    "                    logger.warning(f\"Failed to load features for cover {row['cover_id']}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            return feature_data\n",
    "    \n",
    "    def store_similarity_matrix(self, cover_ids: list, similarity_matrix: np.ndarray):\n",
    "        \"\"\"Store similarity scores in database\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            # Clear existing similarities\n",
    "            conn.execute(\"DELETE FROM visual_similarities\")\n",
    "            \n",
    "            # Store top similarities for each cover\n",
    "            for i, cover_id_1 in enumerate(cover_ids):\n",
    "                similarities = similarity_matrix[i]\n",
    "                \n",
    "                # Get top 10 most similar covers (excluding self)\n",
    "                similar_indices = np.argsort(similarities)[-11:-1][::-1]  # Top 10, excluding self\n",
    "                \n",
    "                for j in similar_indices:\n",
    "                    if similarities[j] > 0.1:  # Only store meaningful similarities\n",
    "                        cover_id_2 = cover_ids[j]\n",
    "                        similarity_score = similarities[j]\n",
    "                        \n",
    "                        conn.execute(\"\"\"\n",
    "                            INSERT INTO visual_similarities \n",
    "                            (cover_id_1, cover_id_2, similarity_score, similarity_type)\n",
    "                            VALUES (?, ?, ?, ?)\n",
    "                        \"\"\", (cover_id_1, cover_id_2, similarity_score, 'overall'))\n",
    "            \n",
    "            conn.commit()\n",
    "            logger.info(f\"Stored similarity data for {len(cover_ids)} covers\")\n",
    "\n",
    "# Setup paths (make sure these match your setup)\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DB_PATH = DATA_DIR / 'database' / 'vinyl_catalog.db'\n",
    "\n",
    "# You need the analyzer from Cell 1 - if you haven't run it, run this:\n",
    "from PIL import Image, ImageFilter\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "@dataclass\n",
    "class ImageFeatures:\n",
    "    \"\"\"Container for extracted image features\"\"\"\n",
    "    image_id: str\n",
    "    color_histogram: np.ndarray\n",
    "    texture_features: np.ndarray\n",
    "    edge_features: np.ndarray\n",
    "    dominant_colors: List[Tuple[int, int, int]]\n",
    "    brightness: float\n",
    "    contrast: float\n",
    "    saturation: float\n",
    "    complexity_score: float\n",
    "\n",
    "class AlbumCoverAnalyzer:\n",
    "    \"\"\"Computer vision analysis for album covers\"\"\"\n",
    "    \n",
    "    def __init__(self, target_size: Tuple[int, int] = (224, 224)):\n",
    "        self.target_size = target_size\n",
    "        \n",
    "    def extract_color_features(self, image: Image.Image) -> Tuple[np.ndarray, List[Tuple[int, int, int]]]:\n",
    "        \"\"\"Extract color histogram and dominant colors\"\"\"\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        image_resized = image.resize(self.target_size)\n",
    "        img_array = np.array(image_resized)\n",
    "        \n",
    "        # Color histogram (8 bins per channel)\n",
    "        hist_r = np.histogram(img_array[:,:,0], bins=8, range=(0, 256))[0]\n",
    "        hist_g = np.histogram(img_array[:,:,1], bins=8, range=(0, 256))[0]\n",
    "        hist_b = np.histogram(img_array[:,:,2], bins=8, range=(0, 256))[0]\n",
    "        color_hist = np.concatenate([hist_r, hist_g, hist_b])\n",
    "        color_hist = color_hist / np.sum(color_hist) if np.sum(color_hist) > 0 else color_hist\n",
    "        \n",
    "        # Dominant colors using K-means\n",
    "        pixels = img_array.reshape(-1, 3)\n",
    "        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "        kmeans.fit(pixels)\n",
    "        dominant_colors = [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]\n",
    "        \n",
    "        return color_hist, dominant_colors\n",
    "    \n",
    "    def extract_texture_features(self, image: Image.Image) -> np.ndarray:\n",
    "        \"\"\"Extract texture features\"\"\"\n",
    "        gray = image.convert('L').resize(self.target_size)\n",
    "        gray_array = np.array(gray)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        grad_x = cv2.Sobel(gray_array, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(gray_array, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        \n",
    "        # Texture histogram\n",
    "        texture_hist = np.histogram(magnitude, bins=16, range=(0, 255))[0]\n",
    "        texture_hist = texture_hist / np.sum(texture_hist) if np.sum(texture_hist) > 0 else texture_hist\n",
    "        \n",
    "        variance = np.var(gray_array)\n",
    "        mean_gradient = np.mean(magnitude)\n",
    "        \n",
    "        return np.concatenate([texture_hist, [variance / 1000, mean_gradient / 100]])\n",
    "    \n",
    "    def extract_edge_features(self, image: Image.Image) -> np.ndarray:\n",
    "        \"\"\"Extract edge-based features\"\"\"\n",
    "        gray = image.convert('L').resize(self.target_size)\n",
    "        gray_array = np.array(gray)\n",
    "        \n",
    "        edges = cv2.Canny(gray_array, 50, 150)\n",
    "        edge_density = np.sum(edges > 0) / edges.size\n",
    "        \n",
    "        grad_x = cv2.Sobel(gray_array, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(gray_array, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        angles = np.arctan2(grad_y, grad_x)\n",
    "        angle_hist = np.histogram(angles, bins=8, range=(-np.pi, np.pi))[0]\n",
    "        angle_hist = angle_hist / np.sum(angle_hist) if np.sum(angle_hist) > 0 else angle_hist\n",
    "        \n",
    "        return np.concatenate([angle_hist, [edge_density]])\n",
    "    \n",
    "    def extract_global_features(self, image: Image.Image) -> Tuple[float, float, float, float]:\n",
    "        \"\"\"Extract global image properties\"\"\"\n",
    "        rgb_img = image.convert('RGB').resize(self.target_size)\n",
    "        hsv_img = rgb_img.convert('HSV')\n",
    "        \n",
    "        rgb_array = np.array(rgb_img)\n",
    "        hsv_array = np.array(hsv_img)\n",
    "        \n",
    "        brightness = np.mean(rgb_array)\n",
    "        gray = np.mean(rgb_array, axis=2)\n",
    "        contrast = np.std(gray)\n",
    "        saturation = np.mean(hsv_array[:,:,1])\n",
    "        \n",
    "        edges = cv2.Canny(gray.astype(np.uint8), 50, 150)\n",
    "        edge_density = np.sum(edges > 0) / edges.size\n",
    "        color_variance = np.var(rgb_array.reshape(-1, 3), axis=0).mean()\n",
    "        complexity_score = edge_density + (color_variance / 1000)\n",
    "        \n",
    "        return brightness, contrast, saturation, complexity_score\n",
    "    \n",
    "    def analyze_image(self, image: Image.Image, image_id: str):\n",
    "        \"\"\"Complete feature extraction pipeline\"\"\"\n",
    "        try:\n",
    "            color_hist, dominant_colors = self.extract_color_features(image)\n",
    "            texture_features = self.extract_texture_features(image)\n",
    "            edge_features = self.extract_edge_features(image)\n",
    "            brightness, contrast, saturation, complexity = self.extract_global_features(image)\n",
    "            \n",
    "            return ImageFeatures(\n",
    "                image_id=image_id,\n",
    "                color_histogram=color_hist,\n",
    "                texture_features=texture_features,\n",
    "                edge_features=edge_features,\n",
    "                dominant_colors=dominant_colors,\n",
    "                brightness=brightness,\n",
    "                contrast=contrast,\n",
    "                saturation=saturation,\n",
    "                complexity_score=complexity\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to analyze image {image_id}: {e}\")\n",
    "            return ImageFeatures(\n",
    "                image_id=image_id,\n",
    "                color_histogram=np.zeros(24),\n",
    "                texture_features=np.zeros(18),\n",
    "                edge_features=np.zeros(9),\n",
    "                dominant_colors=[(0, 0, 0)] * 5,\n",
    "                brightness=0.0,\n",
    "                contrast=0.0,\n",
    "                saturation=0.0,\n",
    "                complexity_score=0.0\n",
    "            )\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = AlbumCoverAnalyzer()\n",
    "\n",
    "# Initialize similarity engine\n",
    "similarity_engine = VisualSimilarityEngine(DB_PATH, analyzer)\n",
    "\n",
    "# Extract features for all covers\n",
    "print(\"Extracting visual features from album covers...\")\n",
    "features_extracted = similarity_engine.extract_features_for_all_covers()\n",
    "\n",
    "# Compute similarity matrix\n",
    "print(\"Computing visual similarities...\")\n",
    "similarity_matrix = similarity_engine.compute_similarity_matrix()\n",
    "\n",
    "print(f\"Visual similarity computation complete!\")\n",
    "print(f\"Feature vectors created for {features_extracted} album covers\")\n",
    "\n",
    "if len(similarity_matrix) > 0:\n",
    "    print(f\"Similarity matrix shape: {similarity_matrix.shape}\")\n",
    "    print(f\"Ready for visual discovery!\")\n",
    "else:\n",
    "    print(\"No similarities computed - need more covers with features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4550d548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual Discovery Interface Ready!\n",
      "Available features:\n",
      "  - find_similar_albums(): Find albums with similar visual style\n",
      "  - get_albums_by_visual_style(): Filter by brightness, saturation, complexity\n",
      "  - get_color_clusters(): Group albums by dominant colors\n",
      "  - search_by_visual_keywords(): Search using descriptive terms\n",
      "\n",
      "Testing the visual discovery system...\n",
      "Found 13 albums with visual features\n",
      "\n",
      "TEST 1: Finding albums similar to 'Hachiko (The Faithtful Dog)' by The Kyoto Connection\n",
      "Similar albums found:\n",
      "  • Charles Atlas - Photosphere (similarity: 1.000)\n",
      "  • Jahzzar - Take Me Higher (similarity: 1.000)\n",
      "  • Bitbasic - Be careful, I've Stood On It Too (similarity: 0.842)\n",
      "  • Eric Skiff - Chibi Ninja (similarity: 0.841)\n",
      "  • Latché Swing - Menilmontant (similarity: 0.818)\n",
      "\n",
      "TEST 2: Searching for 'dark' and 'complex' albums\n",
      "  No albums found matching these criteria\n",
      "\n",
      "TEST 3: Color-based grouping\n",
      "Red/Warm: 2 albums\n",
      "  • Sleeping Policemen - Vogelbird\n",
      "  • alright lover - Snow Wave\n",
      "Green/Natural: 2 albums\n",
      "  • Bitbasic - Be careful, I've Stood On It Too\n",
      "  • Eric Skiff - Chibi Ninja\n",
      "Dark/Monochrome: 9 albums\n",
      "  • The Kyoto Connection - Hachiko (The Faithtful Dog)\n",
      "  • Jahzzar - Take Me Higher\n",
      "\n",
      "TEST 4: Albums with high brightness (150-255)\n",
      "  No bright albums found\n",
      "\n",
      "Visual Discovery System Status:\n",
      "  ✓ Interface initialized\n",
      "  ✓ 13 albums ready for visual search\n",
      "  ✓ Similarity matching operational\n",
      "  ✓ Keyword search operational\n",
      "  ✓ Color clustering operational\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Visual Discovery Interface\n",
    "\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import json\n",
    "\n",
    "class VisualDiscoveryInterface:\n",
    "    \"\"\"Interface for visual album discovery\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: Path):\n",
    "        self.db_path = db_path\n",
    "        \n",
    "    @contextmanager\n",
    "    def get_db_connection(self):\n",
    "        \"\"\"Database connection context manager\"\"\"\n",
    "        conn = sqlite3.connect(str(self.db_path))\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        try:\n",
    "            yield conn\n",
    "        finally:\n",
    "            conn.close()\n",
    "    \n",
    "    def find_similar_albums(self, release_id: int, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Find visually similar albums to a given release\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    r2.release_id, r2.title, r2.artist, r2.album, r2.year, r2.genre,\n",
    "                    ac2.local_path as cover_path,\n",
    "                    vs.similarity_score,\n",
    "                    vf2.brightness, vf2.saturation, vf2.complexity_score\n",
    "                FROM visual_similarities vs\n",
    "                JOIN album_covers ac1 ON vs.cover_id_1 = ac1.cover_id\n",
    "                JOIN album_covers ac2 ON vs.cover_id_2 = ac2.cover_id\n",
    "                JOIN releases r2 ON ac2.release_id = r2.release_id\n",
    "                LEFT JOIN visual_features vf2 ON ac2.cover_id = vf2.cover_id\n",
    "                WHERE ac1.release_id = ?\n",
    "                ORDER BY vs.similarity_score DESC\n",
    "                LIMIT ?\n",
    "            \"\"\", (release_id, limit))\n",
    "            \n",
    "            return [dict(row) for row in cursor.fetchall()]\n",
    "    \n",
    "    def get_albums_by_visual_style(self, \n",
    "                                  brightness_range: Tuple[float, float] = None,\n",
    "                                  saturation_range: Tuple[float, float] = None,\n",
    "                                  complexity_range: Tuple[float, float] = None,\n",
    "                                  genre: str = None,\n",
    "                                  limit: int = 20) -> List[Dict]:\n",
    "        \"\"\"Find albums by visual characteristics\"\"\"\n",
    "        \n",
    "        where_clauses = []\n",
    "        params = []\n",
    "        \n",
    "        if brightness_range:\n",
    "            where_clauses.append(\"vf.brightness BETWEEN ? AND ?\")\n",
    "            params.extend(brightness_range)\n",
    "            \n",
    "        if saturation_range:\n",
    "            where_clauses.append(\"vf.saturation BETWEEN ? AND ?\")\n",
    "            params.extend(saturation_range)\n",
    "            \n",
    "        if complexity_range:\n",
    "            where_clauses.append(\"vf.complexity_score BETWEEN ? AND ?\")\n",
    "            params.extend(complexity_range)\n",
    "            \n",
    "        if genre:\n",
    "            where_clauses.append(\"r.genre LIKE ?\")\n",
    "            params.append(f\"%{genre}%\")\n",
    "        \n",
    "        where_clause = \" AND \".join(where_clauses) if where_clauses else \"1=1\"\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT \n",
    "                r.release_id, r.title, r.artist, r.album, r.year, r.genre,\n",
    "                ac.local_path as cover_path,\n",
    "                vf.brightness, vf.saturation, vf.complexity_score,\n",
    "                vf.dominant_colors\n",
    "            FROM releases r\n",
    "            JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "            JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "            WHERE {where_clause}\n",
    "            ORDER BY r.popularity_score DESC\n",
    "            LIMIT ?\n",
    "        \"\"\"\n",
    "        \n",
    "        params.append(limit)\n",
    "        \n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(query, params)\n",
    "            return [dict(row) for row in cursor.fetchall()]\n",
    "    \n",
    "    def get_color_clusters(self) -> Dict[str, List[Dict]]:\n",
    "        \"\"\"Get albums grouped by dominant color themes\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    r.release_id, r.title, r.artist, r.album, r.year, r.genre,\n",
    "                    ac.local_path as cover_path,\n",
    "                    vf.dominant_colors, vf.brightness, vf.saturation\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                WHERE vf.dominant_colors IS NOT NULL\n",
    "                ORDER BY r.popularity_score DESC\n",
    "                LIMIT 50\n",
    "            \"\"\")\n",
    "            \n",
    "            albums = [dict(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            # Group by color themes\n",
    "            color_groups = {\n",
    "                'Red/Warm': [],\n",
    "                'Blue/Cool': [],\n",
    "                'Green/Natural': [],\n",
    "                'Dark/Monochrome': [],\n",
    "                'Bright/Colorful': []\n",
    "            }\n",
    "            \n",
    "            for album in albums:\n",
    "                try:\n",
    "                    dominant_colors = json.loads(album['dominant_colors'])\n",
    "                    primary_color = dominant_colors[0]  # Most dominant color\n",
    "                    \n",
    "                    r, g, b = primary_color\n",
    "                    brightness = album['brightness']\n",
    "                    \n",
    "                    # Simple color classification\n",
    "                    if brightness < 80:  # Dark\n",
    "                        color_groups['Dark/Monochrome'].append(album)\n",
    "                    elif r > g and r > b:  # Red dominant\n",
    "                        color_groups['Red/Warm'].append(album)\n",
    "                    elif b > r and b > g:  # Blue dominant\n",
    "                        color_groups['Blue/Cool'].append(album)\n",
    "                    elif g > r and g > b:  # Green dominant\n",
    "                        color_groups['Green/Natural'].append(album)\n",
    "                    else:  # Mixed/colorful\n",
    "                        color_groups['Bright/Colorful'].append(album)\n",
    "                        \n",
    "                except (json.JSONDecodeError, IndexError):\n",
    "                    color_groups['Dark/Monochrome'].append(album)\n",
    "            \n",
    "            return color_groups\n",
    "    \n",
    "    def search_by_visual_keywords(self, keywords: List[str], limit: int = 20) -> List[Dict]:\n",
    "        \"\"\"Search albums by visual description keywords\"\"\"\n",
    "        # Map keywords to visual characteristics\n",
    "        keyword_mapping = {\n",
    "            'dark': {'brightness_range': (0, 100)},\n",
    "            'bright': {'brightness_range': (150, 255)},\n",
    "            'colorful': {'saturation_range': (100, 255)},\n",
    "            'monochrome': {'saturation_range': (0, 50)},\n",
    "            'complex': {'complexity_range': (0.5, 2.0)},\n",
    "            'simple': {'complexity_range': (0.0, 0.3)},\n",
    "            'vibrant': {'saturation_range': (120, 255), 'brightness_range': (100, 200)},\n",
    "            'muted': {'saturation_range': (0, 80), 'brightness_range': (50, 150)}\n",
    "        }\n",
    "        \n",
    "        # Combine criteria from keywords\n",
    "        criteria = {}\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in keyword_mapping:\n",
    "                for key, value in keyword_mapping[keyword.lower()].items():\n",
    "                    if key not in criteria:\n",
    "                        criteria[key] = value\n",
    "                    else:\n",
    "                        # Intersect ranges\n",
    "                        if isinstance(value, tuple) and isinstance(criteria[key], tuple):\n",
    "                            criteria[key] = (\n",
    "                                max(value[0], criteria[key][0]),\n",
    "                                min(value[1], criteria[key][1])\n",
    "                            )\n",
    "        \n",
    "        return self.get_albums_by_visual_style(limit=limit, **criteria)\n",
    "\n",
    "    def get_all_albums_with_covers(self) -> List[Dict]:\n",
    "        \"\"\"Get all albums that have visual features for testing\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    r.release_id, r.title, r.artist, r.album, r.year, r.genre,\n",
    "                    ac.local_path as cover_path,\n",
    "                    vf.brightness, vf.saturation, vf.complexity_score\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                ORDER BY r.popularity_score DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            return [dict(row) for row in cursor.fetchall()]\n",
    "\n",
    "# Initialize paths\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DB_PATH = DATA_DIR / 'database' / 'vinyl_catalog.db'\n",
    "\n",
    "# Initialize visual discovery interface\n",
    "discovery = VisualDiscoveryInterface(DB_PATH)\n",
    "\n",
    "print(\"Visual Discovery Interface Ready!\")\n",
    "print(\"Available features:\")\n",
    "print(\"  - find_similar_albums(): Find albums with similar visual style\")\n",
    "print(\"  - get_albums_by_visual_style(): Filter by brightness, saturation, complexity\")\n",
    "print(\"  - get_color_clusters(): Group albums by dominant colors\")\n",
    "print(\"  - search_by_visual_keywords(): Search using descriptive terms\")\n",
    "\n",
    "# Test the interface with your data\n",
    "print(\"\\nTesting the visual discovery system...\")\n",
    "\n",
    "# Get all albums with covers for testing\n",
    "all_albums = discovery.get_all_albums_with_covers()\n",
    "print(f\"Found {len(all_albums)} albums with visual features\")\n",
    "\n",
    "if all_albums:\n",
    "    # Test 1: Find similar albums\n",
    "    test_album = all_albums[0]\n",
    "    print(f\"\\nTEST 1: Finding albums similar to '{test_album['title']}' by {test_album['artist']}\")\n",
    "    \n",
    "    similar_albums = discovery.find_similar_albums(test_album['release_id'], limit=5)\n",
    "    if similar_albums:\n",
    "        print(\"Similar albums found:\")\n",
    "        for album in similar_albums:\n",
    "            print(f\"  • {album['artist']} - {album['title']} \"\n",
    "                  f\"(similarity: {album['similarity_score']:.3f})\")\n",
    "    else:\n",
    "        print(\"  No similar albums found\")\n",
    "    \n",
    "    # Test 2: Search by visual keywords\n",
    "    print(f\"\\nTEST 2: Searching for 'dark' and 'complex' albums\")\n",
    "    keyword_results = discovery.search_by_visual_keywords(['dark', 'complex'], limit=5)\n",
    "    if keyword_results:\n",
    "        print(\"Albums matching 'dark' and 'complex':\")\n",
    "        for album in keyword_results:\n",
    "            print(f\"  • {album['artist']} - {album['title']} \"\n",
    "                  f\"(brightness: {album['brightness']:.1f}, complexity: {album['complexity_score']:.3f})\")\n",
    "    else:\n",
    "        print(\"  No albums found matching these criteria\")\n",
    "    \n",
    "    # Test 3: Color clustering\n",
    "    print(f\"\\nTEST 3: Color-based grouping\")\n",
    "    color_groups = discovery.get_color_clusters()\n",
    "    for color_theme, albums in color_groups.items():\n",
    "        if albums:\n",
    "            print(f\"{color_theme}: {len(albums)} albums\")\n",
    "            for album in albums[:2]:  # Show first 2 in each category\n",
    "                print(f\"  • {album['artist']} - {album['title']}\")\n",
    "    \n",
    "    # Test 4: Visual style filtering\n",
    "    print(f\"\\nTEST 4: Albums with high brightness (150-255)\")\n",
    "    bright_albums = discovery.get_albums_by_visual_style(\n",
    "        brightness_range=(150, 255), \n",
    "        limit=5\n",
    "    )\n",
    "    if bright_albums:\n",
    "        print(\"Bright albums:\")\n",
    "        for album in bright_albums:\n",
    "            print(f\"  • {album['artist']} - {album['title']} \"\n",
    "                  f\"(brightness: {album['brightness']:.1f})\")\n",
    "    else:\n",
    "        print(\"  No bright albums found\")\n",
    "\n",
    "else:\n",
    "    print(\"No albums with visual features found. Make sure Cell 3 completed successfully.\")\n",
    "\n",
    "print(f\"\\nVisual Discovery System Status:\")\n",
    "print(f\"  ✓ Interface initialized\")\n",
    "print(f\"  ✓ {len(all_albums)} albums ready for visual search\")\n",
    "print(f\"  ✓ Similarity matching operational\")\n",
    "print(f\"  ✓ Keyword search operational\")\n",
    "print(f\"  ✓ Color clustering operational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d72e6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:37:31,007 - INFO - Stored clustering results: 4 clusters, cluster_id 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visual analytics report...\n",
      "\n",
      "============================================================\n",
      "VISUAL ANALYSIS REPORT\n",
      "Generated: 2025-09-03 21:37:30\n",
      "============================================================\n",
      "\n",
      "SUMMARY STATISTICS:\n",
      "  Total album covers analyzed: 13\n",
      "  Average brightness: 69.8 (range: 41.8-95.8)\n",
      "  Average saturation: 165.9 (range: 0.0-255.0)\n",
      "  Average complexity: 0.225\n",
      "\n",
      "VISUAL TRENDS BY GENRE:\n",
      "  Classical       ( 3 albums): brightness= 56.9, saturation=255.0, complexity=0.147\n",
      "  Unknown         ( 3 albums): brightness= 55.4, saturation=  0.0, complexity=0.234\n",
      "  Electronic      ( 2 albums): brightness= 95.8, saturation=175.8, complexity=0.392\n",
      "  Pop             ( 2 albums): brightness= 94.8, saturation=237.0, complexity=0.312\n",
      "  Folk            ( 1 albums): brightness= 41.8, saturation=196.3, complexity=0.101\n",
      "  Jazz            ( 1 albums): brightness= 70.2, saturation=170.2, complexity=0.121\n",
      "  Rock            ( 1 albums): brightness= 76.8, saturation=199.3, complexity=0.147\n",
      "\n",
      "VISUAL TRENDS BY DECADE:\n",
      "  2000s  ( 4 albums): brightness= 69.6, saturation=150.3, complexity=0.228\n",
      "  2010s  ( 4 albums): brightness= 75.8, saturation=166.9, complexity=0.274\n",
      "\n",
      "VISUAL CLUSTERS DISCOVERED:\n",
      "Found 4 distinct visual styles:\n",
      "\n",
      "  Cluster 0: 5 albums\n",
      "    Dominant genre: Classical\n",
      "    Visual profile: brightness=72.0, saturation=247.8, complexity=0.213\n",
      "    Time period: 2007-2012\n",
      "    Sample albums:\n",
      "      • alright lover - Snow Wave (2011)\n",
      "      • Lovira - All things considered (2012)\n",
      "      • Kevin MacLeod - P. I. Tchaikovsky: Dance of the Sugar Plum Fairy (None)\n",
      "\n",
      "  Cluster 1: 3 albums\n",
      "    Dominant genre: Unknown\n",
      "    Visual profile: brightness=55.4, saturation=0.0, complexity=0.234\n",
      "    Time period: 2004-2013\n",
      "    Sample albums:\n",
      "      • Jahzzar - Take Me Higher (None)\n",
      "      • The Kyoto Connection - Hachiko (The Faithtful Dog) (2013)\n",
      "      • Charles Atlas - Photosphere (2004)\n",
      "\n",
      "  Cluster 2: 2 albums\n",
      "    Dominant genre: Electronic\n",
      "    Visual profile: brightness=95.8, saturation=175.8, complexity=0.392\n",
      "    Time period: 2005-2012\n",
      "    Sample albums:\n",
      "      • Bitbasic - Be careful, I've Stood On It Too (2012)\n",
      "      • Eric Skiff - Chibi Ninja (2005)\n",
      "\n",
      "  Cluster 3: 3 albums\n",
      "    Dominant genre: Jazz\n",
      "    Visual profile: brightness=62.9, saturation=188.6, complexity=0.123\n",
      "    Time period: 2008-2008\n",
      "    Sample albums:\n",
      "      • Latché Swing - Menilmontant (2008)\n",
      "      • Michett - Demolition (None)\n",
      "      • David Szesztay - Waiting (None)\n",
      "\n",
      "KEY INSIGHTS:\n",
      "  • Brightest covers: Electronic (avg brightness: 95.8)\n",
      "  • Darkest covers: Folk (avg brightness: 41.8)\n",
      "  • Most complex covers: Electronic (avg complexity: 0.392)\n",
      "  • Brightness trend: increased by 6.2 from 2000s to 2010s\n",
      "  • Complexity trend: increased by 0.046 from 2000s to 2010s\n",
      "\n",
      "VISUAL ANALYTICS COMPLETE!\n",
      "  • Genre analysis: 7 genres analyzed\n",
      "  • Temporal analysis: 2 decades covered\n",
      "  • Clustering: 4 visual styles identified\n",
      "  • Ready for advanced visual discovery features!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Visual Analytics and Clustering\n",
    "\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "import json\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Dict, List, Any\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class VisualAnalytics:\n",
    "    \"\"\"Analytics and visualization for album cover patterns\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: Path):\n",
    "        self.db_path = db_path\n",
    "        \n",
    "    @contextmanager\n",
    "    def get_db_connection(self):\n",
    "        \"\"\"Database connection context manager\"\"\"\n",
    "        conn = sqlite3.connect(str(self.db_path))\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        try:\n",
    "            yield conn\n",
    "        finally:\n",
    "            conn.close()\n",
    "    \n",
    "    def analyze_visual_trends_by_genre(self) -> Dict[str, Dict]:\n",
    "        \"\"\"Analyze visual characteristics by music genre\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    r.genre,\n",
    "                    AVG(vf.brightness) as avg_brightness,\n",
    "                    AVG(vf.saturation) as avg_saturation,\n",
    "                    AVG(vf.complexity_score) as avg_complexity,\n",
    "                    AVG(vf.contrast_score) as avg_contrast,\n",
    "                    COUNT(*) as album_count\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                WHERE r.genre IS NOT NULL\n",
    "                GROUP BY r.genre\n",
    "                HAVING COUNT(*) >= 1\n",
    "                ORDER BY album_count DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            genre_analysis = {}\n",
    "            for row in cursor.fetchall():\n",
    "                genre_analysis[row['genre']] = {\n",
    "                    'avg_brightness': row['avg_brightness'],\n",
    "                    'avg_saturation': row['avg_saturation'],\n",
    "                    'avg_complexity': row['avg_complexity'],\n",
    "                    'avg_contrast': row['avg_contrast'],\n",
    "                    'album_count': row['album_count']\n",
    "                }\n",
    "            \n",
    "            return genre_analysis\n",
    "    \n",
    "    def analyze_visual_trends_by_decade(self) -> Dict[str, Dict]:\n",
    "        \"\"\"Analyze how album cover styles changed over time\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    (r.year / 10) * 10 as decade,\n",
    "                    AVG(vf.brightness) as avg_brightness,\n",
    "                    AVG(vf.saturation) as avg_saturation,\n",
    "                    AVG(vf.complexity_score) as avg_complexity,\n",
    "                    AVG(vf.contrast_score) as avg_contrast,\n",
    "                    COUNT(*) as album_count\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                WHERE r.year IS NOT NULL AND r.year >= 1960 AND r.year <= 2020\n",
    "                GROUP BY decade\n",
    "                ORDER BY decade\n",
    "            \"\"\")\n",
    "            \n",
    "            decade_analysis = {}\n",
    "            for row in cursor.fetchall():\n",
    "                decade_analysis[f\"{int(row['decade'])}s\"] = {\n",
    "                    'avg_brightness': row['avg_brightness'],\n",
    "                    'avg_saturation': row['avg_saturation'],\n",
    "                    'avg_complexity': row['avg_complexity'],\n",
    "                    'avg_contrast': row['avg_contrast'],\n",
    "                    'album_count': row['album_count']\n",
    "                }\n",
    "            \n",
    "            return decade_analysis\n",
    "    \n",
    "    def create_visual_clusters(self, n_clusters: int = 5) -> Dict[int, List[Dict]]:\n",
    "        \"\"\"Create visual clusters using K-means\"\"\"\n",
    "        # Load all visual features\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    ac.cover_id, r.release_id, r.title, r.artist, r.album, r.genre, r.year,\n",
    "                    vf.color_histogram, vf.texture_features, vf.edge_features,\n",
    "                    vf.brightness, vf.saturation, vf.complexity_score, vf.contrast_score,\n",
    "                    ac.local_path\n",
    "                FROM album_covers ac\n",
    "                JOIN releases r ON ac.release_id = r.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "            \"\"\")\n",
    "            \n",
    "            data = [dict(row) for row in cursor.fetchall()]\n",
    "        \n",
    "        if len(data) < n_clusters:\n",
    "            logger.warning(f\"Not enough data for {n_clusters} clusters. Found {len(data)} albums.\")\n",
    "            n_clusters = max(2, len(data) // 2)\n",
    "        \n",
    "        # Prepare feature vectors\n",
    "        feature_vectors = []\n",
    "        for item in data:\n",
    "            try:\n",
    "                color_hist = np.array(json.loads(item['color_histogram']))\n",
    "                texture_feat = np.array(json.loads(item['texture_features']))\n",
    "                edge_feat = np.array(json.loads(item['edge_features']))\n",
    "                \n",
    "                # Combine features\n",
    "                combined = np.concatenate([\n",
    "                    color_hist,\n",
    "                    texture_feat,\n",
    "                    edge_feat,\n",
    "                    [item['brightness'] / 255, \n",
    "                     item['saturation'] / 255,\n",
    "                     item['complexity_score'],\n",
    "                     item['contrast_score'] / 100]\n",
    "                ])\n",
    "                feature_vectors.append(combined)\n",
    "            except (json.JSONDecodeError, ValueError) as e:\n",
    "                logger.warning(f\"Failed to parse features for {item['title']}: {e}\")\n",
    "                # Use default features\n",
    "                feature_vectors.append(np.zeros(55))  # Approximate feature vector size\n",
    "        \n",
    "        # Perform K-means clustering\n",
    "        feature_matrix = np.array(feature_vectors)\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "        \n",
    "        # Organize results by cluster\n",
    "        clusters = {}\n",
    "        for i, label in enumerate(cluster_labels):\n",
    "            if label not in clusters:\n",
    "                clusters[label] = []\n",
    "            \n",
    "            album_data = data[i].copy()\n",
    "            album_data['cluster_label'] = int(label)\n",
    "            album_data['distance_to_center'] = float(\n",
    "                np.linalg.norm(feature_vectors[i] - kmeans.cluster_centers_[label])\n",
    "            )\n",
    "            clusters[label].append(album_data)\n",
    "        \n",
    "        # Store clustering results in database\n",
    "        self.store_clustering_results(clusters, n_clusters)\n",
    "        \n",
    "        return clusters\n",
    "    \n",
    "    def store_clustering_results(self, clusters: Dict[int, List[Dict]], n_clusters: int):\n",
    "        \"\"\"Store clustering results in database\"\"\"\n",
    "        with self.get_db_connection() as conn:\n",
    "            # Create cluster record\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                INSERT INTO visual_clusters (cluster_method, n_clusters, cluster_params)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\", ('kmeans', n_clusters, json.dumps({'n_clusters': n_clusters, 'random_state': 42})))\n",
    "            \n",
    "            cluster_id = cursor.lastrowid\n",
    "            \n",
    "            # Store cluster assignments\n",
    "            for cluster_label, albums in clusters.items():\n",
    "                for album in albums:\n",
    "                    conn.execute(\"\"\"\n",
    "                        INSERT OR REPLACE INTO cluster_assignments \n",
    "                        (cover_id, cluster_id, cluster_label, distance_to_center)\n",
    "                        VALUES (?, ?, ?, ?)\n",
    "                    \"\"\", (\n",
    "                        album['cover_id'],\n",
    "                        cluster_id,\n",
    "                        cluster_label,\n",
    "                        album['distance_to_center']\n",
    "                    ))\n",
    "            \n",
    "            conn.commit()\n",
    "            logger.info(f\"Stored clustering results: {n_clusters} clusters, cluster_id {cluster_id}\")\n",
    "    \n",
    "    def get_cluster_characteristics(self, clusters: Dict[int, List[Dict]]) -> Dict[int, Dict]:\n",
    "        \"\"\"Analyze the characteristics of each cluster\"\"\"\n",
    "        cluster_stats = {}\n",
    "        \n",
    "        for cluster_id, albums in clusters.items():\n",
    "            if not albums:\n",
    "                continue\n",
    "                \n",
    "            # Calculate statistics for this cluster\n",
    "            brightness_values = [a['brightness'] for a in albums if a['brightness'] is not None]\n",
    "            saturation_values = [a['saturation'] for a in albums if a['saturation'] is not None]\n",
    "            complexity_values = [a['complexity_score'] for a in albums if a['complexity_score'] is not None]\n",
    "            \n",
    "            genres = [a['genre'] for a in albums if a['genre']]\n",
    "            years = [a['year'] for a in albums if a['year'] and a['year'] > 0]\n",
    "            \n",
    "            # Most common genre\n",
    "            genre_counts = {}\n",
    "            for genre in genres:\n",
    "                genre_counts[genre] = genre_counts.get(genre, 0) + 1\n",
    "            dominant_genre = max(genre_counts.items(), key=lambda x: x[1])[0] if genre_counts else \"Mixed\"\n",
    "            \n",
    "            cluster_stats[cluster_id] = {\n",
    "                'album_count': len(albums),\n",
    "                'dominant_genre': dominant_genre,\n",
    "                'avg_brightness': np.mean(brightness_values) if brightness_values else 0,\n",
    "                'avg_saturation': np.mean(saturation_values) if saturation_values else 0,\n",
    "                'avg_complexity': np.mean(complexity_values) if complexity_values else 0,\n",
    "                'avg_year': np.mean(years) if years else 0,\n",
    "                'year_range': (min(years), max(years)) if years else (0, 0),\n",
    "                'sample_albums': albums[:3]  # Show first 3 albums as examples\n",
    "            }\n",
    "        \n",
    "        return cluster_stats\n",
    "    \n",
    "    def generate_visual_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive visual analysis report\"\"\"\n",
    "        report = {\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'genre_analysis': self.analyze_visual_trends_by_genre(),\n",
    "            'decade_analysis': self.analyze_visual_trends_by_decade(),\n",
    "            'clusters': self.create_visual_clusters(n_clusters=4)\n",
    "        }\n",
    "        \n",
    "        # Add summary statistics\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(*) as total_covers,\n",
    "                    AVG(brightness) as avg_brightness,\n",
    "                    AVG(saturation) as avg_saturation,\n",
    "                    AVG(complexity_score) as avg_complexity,\n",
    "                    MIN(brightness) as min_brightness,\n",
    "                    MAX(brightness) as max_brightness,\n",
    "                    MIN(saturation) as min_saturation,\n",
    "                    MAX(saturation) as max_saturation\n",
    "                FROM visual_features\n",
    "            \"\"\")\n",
    "            \n",
    "            stats = dict(cursor.fetchone())\n",
    "            report['summary_statistics'] = stats\n",
    "        \n",
    "        # Add cluster characteristics\n",
    "        report['cluster_characteristics'] = self.get_cluster_characteristics(report['clusters'])\n",
    "        \n",
    "        return report\n",
    "\n",
    "# Initialize paths\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DB_PATH = DATA_DIR / 'database' / 'vinyl_catalog.db'\n",
    "\n",
    "# Initialize analytics\n",
    "analytics = VisualAnalytics(DB_PATH)\n",
    "\n",
    "print(\"Generating visual analytics report...\")\n",
    "visual_report = analytics.generate_visual_report()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"VISUAL ANALYSIS REPORT\")\n",
    "print(f\"Generated: {visual_report['timestamp']}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Display summary statistics\n",
    "stats = visual_report['summary_statistics']\n",
    "print(f\"\\nSUMMARY STATISTICS:\")\n",
    "print(f\"  Total album covers analyzed: {stats['total_covers']}\")\n",
    "print(f\"  Average brightness: {stats['avg_brightness']:.1f} (range: {stats['min_brightness']:.1f}-{stats['max_brightness']:.1f})\")\n",
    "print(f\"  Average saturation: {stats['avg_saturation']:.1f} (range: {stats['min_saturation']:.1f}-{stats['max_saturation']:.1f})\")\n",
    "print(f\"  Average complexity: {stats['avg_complexity']:.3f}\")\n",
    "\n",
    "# Display genre trends\n",
    "print(f\"\\nVISUAL TRENDS BY GENRE:\")\n",
    "genre_analysis = visual_report['genre_analysis']\n",
    "for genre, data in list(genre_analysis.items())[:10]:  # Show top 10 genres\n",
    "    print(f\"  {genre:15} ({data['album_count']:2d} albums): \"\n",
    "          f\"brightness={data['avg_brightness']:5.1f}, \"\n",
    "          f\"saturation={data['avg_saturation']:5.1f}, \"\n",
    "          f\"complexity={data['avg_complexity']:.3f}\")\n",
    "\n",
    "# Display decade trends\n",
    "print(f\"\\nVISUAL TRENDS BY DECADE:\")\n",
    "decade_analysis = visual_report['decade_analysis']\n",
    "for decade, data in decade_analysis.items():\n",
    "    print(f\"  {decade:6} ({data['album_count']:2d} albums): \"\n",
    "          f\"brightness={data['avg_brightness']:5.1f}, \"\n",
    "          f\"saturation={data['avg_saturation']:5.1f}, \"\n",
    "          f\"complexity={data['avg_complexity']:.3f}\")\n",
    "\n",
    "# Display cluster information\n",
    "clusters = visual_report['clusters']\n",
    "cluster_chars = visual_report['cluster_characteristics']\n",
    "print(f\"\\nVISUAL CLUSTERS DISCOVERED:\")\n",
    "print(f\"Found {len(clusters)} distinct visual styles:\")\n",
    "\n",
    "for cluster_id in sorted(cluster_chars.keys()):\n",
    "    data = cluster_chars[cluster_id]\n",
    "    print(f\"\\n  Cluster {cluster_id}: {data['album_count']} albums\")\n",
    "    print(f\"    Dominant genre: {data['dominant_genre']}\")\n",
    "    print(f\"    Visual profile: brightness={data['avg_brightness']:.1f}, \"\n",
    "          f\"saturation={data['avg_saturation']:.1f}, \"\n",
    "          f\"complexity={data['avg_complexity']:.3f}\")\n",
    "    \n",
    "    if data['year_range'][0] > 0:\n",
    "        print(f\"    Time period: {int(data['year_range'][0])}-{int(data['year_range'][1])}\")\n",
    "    \n",
    "    print(f\"    Sample albums:\")\n",
    "    for album in data['sample_albums']:\n",
    "        print(f\"      • {album['artist']} - {album['title']} ({album['year']})\")\n",
    "\n",
    "print(f\"\\nKEY INSIGHTS:\")\n",
    "\n",
    "# Identify most distinctive genre characteristics\n",
    "if genre_analysis:\n",
    "    brightest_genre = max(genre_analysis.items(), key=lambda x: x[1]['avg_brightness'])\n",
    "    darkest_genre = min(genre_analysis.items(), key=lambda x: x[1]['avg_brightness'])\n",
    "    most_complex_genre = max(genre_analysis.items(), key=lambda x: x[1]['avg_complexity'])\n",
    "    \n",
    "    print(f\"  • Brightest covers: {brightest_genre[0]} (avg brightness: {brightest_genre[1]['avg_brightness']:.1f})\")\n",
    "    print(f\"  • Darkest covers: {darkest_genre[0]} (avg brightness: {darkest_genre[1]['avg_brightness']:.1f})\")\n",
    "    print(f\"  • Most complex covers: {most_complex_genre[0]} (avg complexity: {most_complex_genre[1]['avg_complexity']:.3f})\")\n",
    "\n",
    "# Identify temporal trends\n",
    "if len(decade_analysis) > 1:\n",
    "    decades = sorted(decade_analysis.items())\n",
    "    if len(decades) >= 2:\n",
    "        earliest = decades[0]\n",
    "        latest = decades[-1]\n",
    "        brightness_change = latest[1]['avg_brightness'] - earliest[1]['avg_brightness']\n",
    "        complexity_change = latest[1]['avg_complexity'] - earliest[1]['avg_complexity']\n",
    "        \n",
    "        print(f\"  • Brightness trend: {'increased' if brightness_change > 0 else 'decreased'} by {abs(brightness_change):.1f} from {earliest[0]} to {latest[0]}\")\n",
    "        print(f\"  • Complexity trend: {'increased' if complexity_change > 0 else 'decreased'} by {abs(complexity_change):.3f} from {earliest[0]} to {latest[0]}\")\n",
    "\n",
    "print(f\"\\nVISUAL ANALYTICS COMPLETE!\")\n",
    "print(f\"  • Genre analysis: {len(genre_analysis)} genres analyzed\")\n",
    "print(f\"  • Temporal analysis: {len(decade_analysis)} decades covered\")\n",
    "print(f\"  • Clustering: {len(clusters)} visual styles identified\")\n",
    "print(f\"  • Ready for advanced visual discovery features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - Demo Interface and Usage Examples\n",
    "\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "import random\n",
    "import json\n",
    "\n",
    "class VisualDiscoveryDemo:\n",
    "    \"\"\"Demo interface showing visual discovery capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, discovery_interface):\n",
    "        self.discovery = discovery_interface\n",
    "    \n",
    "    def demo_similar_albums(self):\n",
    "        \"\"\"Demonstrate finding similar albums\"\"\"\n",
    "        print(\"\\n🔍 VISUAL SIMILARITY DEMO\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Get a random album to start with\n",
    "        with self.discovery.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT r.release_id, r.title, r.artist, r.genre, r.year,\n",
    "                       vf.brightness, vf.saturation, vf.complexity_score\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                ORDER BY RANDOM()\n",
    "                LIMIT 1\n",
    "            \"\"\")\n",
    "            \n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                seed_album = dict(result)\n",
    "            else:\n",
    "                print(\"No albums available for demo\")\n",
    "                return\n",
    "        \n",
    "        print(f\"Finding albums visually similar to:\")\n",
    "        print(f\"  '{seed_album['title']}' by {seed_album['artist']} ({seed_album['year']})\")\n",
    "        print(f\"  Genre: {seed_album['genre']}\")\n",
    "        print(f\"  Visual profile: brightness={seed_album['brightness']:.1f}, \"\n",
    "              f\"saturation={seed_album['saturation']:.1f}, \"\n",
    "              f\"complexity={seed_album['complexity_score']:.3f}\")\n",
    "        \n",
    "        # Find similar albums\n",
    "        similar = self.discovery.find_similar_albums(seed_album['release_id'], limit=5)\n",
    "        \n",
    "        if similar:\n",
    "            print(f\"\\nVisually similar albums:\")\n",
    "            for i, album in enumerate(similar, 1):\n",
    "                print(f\"  {i}. {album['artist']} - {album['title']} ({album['year']})\")\n",
    "                print(f\"     Similarity: {album['similarity_score']:.3f} | \"\n",
    "                      f\"Brightness: {album['brightness']:.1f} | \"\n",
    "                      f\"Genre: {album['genre']}\")\n",
    "        else:\n",
    "            print(\"  No similar albums found\")\n",
    "    \n",
    "    def demo_visual_search(self):\n",
    "        \"\"\"Demonstrate visual characteristic search\"\"\"\n",
    "        print(f\"\\n🎨 VISUAL CHARACTERISTIC SEARCH DEMO\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Search by visual keywords\n",
    "        search_terms = ['dark', 'complex']\n",
    "        print(f\"Searching for albums that are: {', '.join(search_terms)}\")\n",
    "        \n",
    "        results = self.discovery.search_by_visual_keywords(search_terms, limit=5)\n",
    "        \n",
    "        if results:\n",
    "            print(f\"\\nFound {len(results)} matching albums:\")\n",
    "            for album in results:\n",
    "                print(f\"  • {album['artist']} - {album['title']} ({album['genre']})\")\n",
    "                print(f\"    Visual metrics: brightness={album['brightness']:.1f}, \"\n",
    "                      f\"saturation={album['saturation']:.1f}, \"\n",
    "                      f\"complexity={album['complexity_score']:.3f}\")\n",
    "        else:\n",
    "            print(\"  No albums found matching these criteria\")\n",
    "        \n",
    "        # Try another search\n",
    "        print(f\"\\nSearching for 'bright' and 'colorful' albums:\")\n",
    "        bright_results = self.discovery.search_by_visual_keywords(['bright', 'colorful'], limit=3)\n",
    "        \n",
    "        if bright_results:\n",
    "            print(f\"Found {len(bright_results)} bright & colorful albums:\")\n",
    "            for album in bright_results:\n",
    "                print(f\"  • {album['artist']} - {album['title']} ({album['genre']})\")\n",
    "                print(f\"    Visual metrics: brightness={album['brightness']:.1f}, \"\n",
    "                      f\"saturation={album['saturation']:.1f}\")\n",
    "    \n",
    "    def demo_color_clustering(self):\n",
    "        \"\"\"Demonstrate color-based grouping\"\"\"\n",
    "        print(f\"\\n🌈 COLOR CLUSTERING DEMO\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        color_groups = self.discovery.get_color_clusters()\n",
    "        \n",
    "        for color_theme, albums in color_groups.items():\n",
    "            if albums:\n",
    "                print(f\"\\n{color_theme} Albums ({len(albums)}):\")\n",
    "                for album in albums[:3]:  # Show first 3 in each category\n",
    "                    dominant_colors = json.loads(album['dominant_colors']) if album['dominant_colors'] else []\n",
    "                    primary_color = dominant_colors[0] if dominant_colors else [0, 0, 0]\n",
    "                    print(f\"  • {album['artist']} - {album['title']}\")\n",
    "                    print(f\"    Primary color: RGB{tuple(primary_color)} | \"\n",
    "                          f\"Brightness: {album['brightness']:.1f}\")\n",
    "    \n",
    "    def demo_advanced_filtering(self):\n",
    "        \"\"\"Demonstrate advanced visual filtering\"\"\"\n",
    "        print(f\"\\n⚙️  ADVANCED VISUAL FILTERING DEMO\")\n",
    "        print(\"=\" * 45)\n",
    "        \n",
    "        # Filter by brightness ranges\n",
    "        print(\"Albums with medium brightness (60-100):\")\n",
    "        medium_bright = self.discovery.get_albums_by_visual_style(\n",
    "            brightness_range=(60, 100), \n",
    "            limit=4\n",
    "        )\n",
    "        for album in medium_bright:\n",
    "            print(f\"  • {album['artist']} - {album['title']} \"\n",
    "                  f\"(brightness: {album['brightness']:.1f})\")\n",
    "        \n",
    "        # Filter by complexity\n",
    "        print(f\"\\nHighly complex album covers (complexity > 0.3):\")\n",
    "        complex_albums = self.discovery.get_albums_by_visual_style(\n",
    "            complexity_range=(0.3, 2.0),\n",
    "            limit=4\n",
    "        )\n",
    "        for album in complex_albums:\n",
    "            print(f\"  • {album['artist']} - {album['title']} \"\n",
    "                  f\"(complexity: {album['complexity_score']:.3f})\")\n",
    "        \n",
    "        # Filter by genre and visual characteristics\n",
    "        print(f\"\\nElectronic albums with high saturation:\")\n",
    "        electronic_colorful = self.discovery.get_albums_by_visual_style(\n",
    "            genre=\"Electronic\",\n",
    "            saturation_range=(150, 255),\n",
    "            limit=3\n",
    "        )\n",
    "        for album in electronic_colorful:\n",
    "            print(f\"  • {album['artist']} - {album['title']} \"\n",
    "                  f\"(saturation: {album['saturation']:.1f})\")\n",
    "    \n",
    "    def demo_statistical_insights(self):\n",
    "        \"\"\"Show statistical insights about the collection\"\"\"\n",
    "        print(f\"\\n📊 COLLECTION INSIGHTS\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        with self.discovery.get_db_connection() as conn:\n",
    "            # Genre distribution\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT r.genre, COUNT(*) as count,\n",
    "                       AVG(vf.brightness) as avg_brightness,\n",
    "                       AVG(vf.saturation) as avg_saturation,\n",
    "                       AVG(vf.complexity_score) as avg_complexity\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                WHERE r.genre IS NOT NULL\n",
    "                GROUP BY r.genre\n",
    "                ORDER BY count DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            genres = [dict(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            print(\"Visual characteristics by genre:\")\n",
    "            for genre in genres:\n",
    "                print(f\"  {genre['genre']} ({genre['count']} albums):\")\n",
    "                print(f\"    Avg brightness: {genre['avg_brightness']:.1f}\")\n",
    "                print(f\"    Avg saturation: {genre['avg_saturation']:.1f}\")\n",
    "                print(f\"    Avg complexity: {genre['avg_complexity']:.3f}\")\n",
    "            \n",
    "            # Extreme examples\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT r.artist, r.title, r.genre, vf.brightness\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                ORDER BY vf.brightness DESC\n",
    "                LIMIT 1\n",
    "            \"\"\")\n",
    "            brightest = dict(cursor.fetchone())\n",
    "            \n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT r.artist, r.title, r.genre, vf.brightness\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                ORDER BY vf.brightness ASC\n",
    "                LIMIT 1\n",
    "            \"\"\")\n",
    "            darkest = dict(cursor.fetchone())\n",
    "            \n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT r.artist, r.title, r.genre, vf.complexity_score\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                ORDER BY vf.complexity_score DESC\n",
    "                LIMIT 1\n",
    "            \"\"\")\n",
    "            most_complex = dict(cursor.fetchone())\n",
    "            \n",
    "            print(f\"\\nExtreme Examples:\")\n",
    "            print(f\"  Brightest cover: {brightest['artist']} - {brightest['title']} \"\n",
    "                  f\"(brightness: {brightest['brightness']:.1f})\")\n",
    "            print(f\"  Darkest cover: {darkest['artist']} - {darkest['title']} \"\n",
    "                  f\"(brightness: {darkest['brightness']:.1f})\")\n",
    "            print(f\"  Most complex cover: {most_complex['artist']} - {most_complex['title']} \"\n",
    "                  f\"(complexity: {most_complex['complexity_score']:.3f})\")\n",
    "\n",
    "# Initialize demo with the discovery interface from Cell 4\n",
    "# (Make sure you've run Cell 4 first)\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DB_PATH = DATA_DIR / 'database' / 'vinyl_catalog.db'\n",
    "\n",
    "# Recreate discovery interface for demo\n",
    "class VisualDiscoveryInterface:\n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "    \n",
    "    @contextmanager\n",
    "    def get_db_connection(self):\n",
    "        conn = sqlite3.connect(str(self.db_path))\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        try:\n",
    "            yield conn\n",
    "        finally:\n",
    "            conn.close()\n",
    "    \n",
    "    def find_similar_albums(self, release_id, limit=10):\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    r2.release_id, r2.title, r2.artist, r2.album, r2.year, r2.genre,\n",
    "                    vs.similarity_score,\n",
    "                    vf2.brightness, vf2.saturation, vf2.complexity_score\n",
    "                FROM visual_similarities vs\n",
    "                JOIN album_covers ac1 ON vs.cover_id_1 = ac1.cover_id\n",
    "                JOIN album_covers ac2 ON vs.cover_id_2 = ac2.cover_id\n",
    "                JOIN releases r2 ON ac2.release_id = r2.release_id\n",
    "                LEFT JOIN visual_features vf2 ON ac2.cover_id = vf2.cover_id\n",
    "                WHERE ac1.release_id = ?\n",
    "                ORDER BY vs.similarity_score DESC\n",
    "                LIMIT ?\n",
    "            \"\"\", (release_id, limit))\n",
    "            return [dict(row) for row in cursor.fetchall()]\n",
    "    \n",
    "    def search_by_visual_keywords(self, keywords, limit=20):\n",
    "        keyword_mapping = {\n",
    "            'dark': {'brightness_range': (0, 100)},\n",
    "            'bright': {'brightness_range': (150, 255)},\n",
    "            'colorful': {'saturation_range': (100, 255)},\n",
    "            'complex': {'complexity_range': (0.3, 2.0)}\n",
    "        }\n",
    "        \n",
    "        criteria = {}\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in keyword_mapping:\n",
    "                for key, value in keyword_mapping[keyword.lower()].items():\n",
    "                    criteria[key] = value\n",
    "        \n",
    "        return self.get_albums_by_visual_style(limit=limit, **criteria)\n",
    "    \n",
    "    def get_albums_by_visual_style(self, brightness_range=None, saturation_range=None, \n",
    "                                 complexity_range=None, genre=None, limit=20):\n",
    "        where_clauses = []\n",
    "        params = []\n",
    "        \n",
    "        if brightness_range:\n",
    "            where_clauses.append(\"vf.brightness BETWEEN ? AND ?\")\n",
    "            params.extend(brightness_range)\n",
    "        if saturation_range:\n",
    "            where_clauses.append(\"vf.saturation BETWEEN ? AND ?\")\n",
    "            params.extend(saturation_range)\n",
    "        if complexity_range:\n",
    "            where_clauses.append(\"vf.complexity_score BETWEEN ? AND ?\")\n",
    "            params.extend(complexity_range)\n",
    "        if genre:\n",
    "            where_clauses.append(\"r.genre LIKE ?\")\n",
    "            params.append(f\"%{genre}%\")\n",
    "        \n",
    "        where_clause = \" AND \".join(where_clauses) if where_clauses else \"1=1\"\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT r.release_id, r.title, r.artist, r.album, r.year, r.genre,\n",
    "                   vf.brightness, vf.saturation, vf.complexity_score, vf.dominant_colors\n",
    "            FROM releases r\n",
    "            JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "            JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "            WHERE {where_clause}\n",
    "            ORDER BY r.popularity_score DESC\n",
    "            LIMIT ?\n",
    "        \"\"\"\n",
    "        \n",
    "        params.append(limit)\n",
    "        \n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(query, params)\n",
    "            return [dict(row) for row in cursor.fetchall()]\n",
    "    \n",
    "    def get_color_clusters(self):\n",
    "        with self.get_db_connection() as conn:\n",
    "            cursor = conn.execute(\"\"\"\n",
    "                SELECT r.release_id, r.title, r.artist, r.year, r.genre,\n",
    "                       vf.dominant_colors, vf.brightness, vf.saturation\n",
    "                FROM releases r\n",
    "                JOIN album_covers ac ON r.release_id = ac.release_id\n",
    "                JOIN visual_features vf ON ac.cover_id = vf.cover_id\n",
    "                WHERE vf.dominant_colors IS NOT NULL\n",
    "                ORDER BY r.popularity_score DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            albums = [dict(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            color_groups = {\n",
    "                'Red/Warm': [],\n",
    "                'Blue/Cool': [],\n",
    "                'Green/Natural': [],\n",
    "                'Dark/Monochrome': [],\n",
    "                'Bright/Colorful': []\n",
    "            }\n",
    "            \n",
    "            for album in albums:\n",
    "                try:\n",
    "                    dominant_colors = json.loads(album['dominant_colors'])\n",
    "                    primary_color = dominant_colors[0]\n",
    "                    r, g, b = primary_color\n",
    "                    brightness = album['brightness']\n",
    "                    \n",
    "                    if brightness < 80:\n",
    "                        color_groups['Dark/Monochrome'].append(album)\n",
    "                    elif r > g and r > b:\n",
    "                        color_groups['Red/Warm'].append(album)\n",
    "                    elif b > r and b > g:\n",
    "                        color_groups['Blue/Cool'].append(album)\n",
    "                    elif g > r and g > b:\n",
    "                        color_groups['Green/Natural'].append(album)\n",
    "                    else:\n",
    "                        color_groups['Bright/Colorful'].append(album)\n",
    "                except (json.JSONDecodeError, IndexError):\n",
    "                    color_groups['Dark/Monochrome'].append(album)\n",
    "            \n",
    "            return color_groups\n",
    "\n",
    "discovery = VisualDiscoveryInterface(DB_PATH)\n",
    "demo = VisualDiscoveryDemo(discovery)\n",
    "\n",
    "print(f\"🎵 ALBUM COVER VISUAL DISCOVERY SYSTEM - COMPLETE DEMO\")\n",
    "print(f\"=\" * 70)\n",
    "print(f\"Computer vision system operational with {13} analyzed covers\")\n",
    "\n",
    "# Run all demonstrations\n",
    "demo.demo_similar_albums()\n",
    "demo.demo_visual_search()\n",
    "demo.demo_color_clustering()\n",
    "demo.demo_advanced_filtering()\n",
    "demo.demo_statistical_insights()\n",
    "\n",
    "print(f\"\\n🚀 VISUAL DISCOVERY FEATURES SUMMARY:\")\n",
    "print(f\"  🔍 Similarity matching: Find albums that 'look like' a target\")\n",
    "print(f\"  🎨 Visual keyword search: Search by descriptive terms\")\n",
    "print(f\"  🌈 Color clustering: Browse by dominant color themes\")\n",
    "print(f\"  ⚙️  Advanced filtering: Filter by brightness, saturation, complexity\")\n",
    "print(f\"  📊 Analytics: Genre trends and statistical insights\")\n",
    "\n",
    "print(f\"\\n💡 POTENTIAL APPLICATIONS:\")\n",
    "print(f\"  • Visual music discovery: 'Show me dark, complex albums'\")\n",
    "print(f\"  • Mood-based browsing: Find albums that match a visual aesthetic\")\n",
    "print(f\"  • Genre analysis: Compare visual styles across music genres\")\n",
    "print(f\"  • Recommendation engine: Suggest based on visual preferences\")\n",
    "print(f\"  • Collection insights: Understand your music's visual landscape\")\n",
    "\n",
    "print(f\"\\n🎯 NEXT STEPS FOR PRODUCTION:\")\n",
    "print(f\"  • Download real album covers from Discogs API\")\n",
    "print(f\"  • Implement CNN-based deep features for better accuracy\")\n",
    "print(f\"  • Build interactive web interface for browsing\")\n",
    "print(f\"  • Add user preference learning\")\n",
    "print(f\"  • Create visual similarity API endpoints\")\n",
    "\n",
    "print(f\"\\n✅ VISUAL DISCOVERY SYSTEM COMPLETE!\")\n",
    "print(f\"   Ready to revolutionize how people discover music through visual similarity!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
